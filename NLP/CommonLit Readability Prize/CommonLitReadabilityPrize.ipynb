{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CommonLitReadabilityPrize.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4883ef61dca94192926fda155531384f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ee97af8324b4aeead9425915cdb95f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20a1a9bca5fd430c8cfeaefd9bbeb4e2",
              "IPY_MODEL_2e3fc8dfcd0b41cc81120db9b6f382e6"
            ]
          }
        },
        "7ee97af8324b4aeead9425915cdb95f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20a1a9bca5fd430c8cfeaefd9bbeb4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_698a826abad94976af0bcb5508f5ee84",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef13a8b475004f4e9b3f7b17538996de"
          }
        },
        "2e3fc8dfcd0b41cc81120db9b6f382e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_653952e5ecdc44eebdd31699725b2058",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:01&lt;00:00, 252B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3286934fed1f4de8b506da1097516a62"
          }
        },
        "698a826abad94976af0bcb5508f5ee84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef13a8b475004f4e9b3f7b17538996de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "653952e5ecdc44eebdd31699725b2058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3286934fed1f4de8b506da1097516a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa386be406d1470f900dc11ad39a63d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a54f9ddf89247628ee6e3ea024b0c39",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2069eb8954e4154b1dd95d8740bab27",
              "IPY_MODEL_b7f629b965004428b1f989ae45b0f019"
            ]
          }
        },
        "1a54f9ddf89247628ee6e3ea024b0c39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2069eb8954e4154b1dd95d8740bab27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d793212ba9e1476c850c6a6ab0de6970",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f3e8e0f01aa4fe990b40e2ade6459e2"
          }
        },
        "b7f629b965004428b1f989ae45b0f019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_07f9b1a3d6e54b85b04240be5c4c0552",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 932kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d69edb3c35a4f368a6e52b71a66266f"
          }
        },
        "d793212ba9e1476c850c6a6ab0de6970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f3e8e0f01aa4fe990b40e2ade6459e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07f9b1a3d6e54b85b04240be5c4c0552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d69edb3c35a4f368a6e52b71a66266f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fc814ebcc694152be2510715788870d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f90c2d2201f843f7a0943a231a34047a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4bc3c3098511403bab8e21ff6227ae93",
              "IPY_MODEL_1f99eb55f66a43678cf826920efa2f6d"
            ]
          }
        },
        "f90c2d2201f843f7a0943a231a34047a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bc3c3098511403bab8e21ff6227ae93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aade9d3503fb4b4a84d68ad4812cba0f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5442caf9ba74dddbc4768d6dc4aa143"
          }
        },
        "1f99eb55f66a43678cf826920efa2f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78113652540e4e9290e6eed4d7f7ce45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [04:22&lt;00:00, 1.74kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c28909eec8b74b3587dfe68f5dc05736"
          }
        },
        "aade9d3503fb4b4a84d68ad4812cba0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5442caf9ba74dddbc4768d6dc4aa143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78113652540e4e9290e6eed4d7f7ce45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c28909eec8b74b3587dfe68f5dc05736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a6abe73d45f4cf39f341e1a621c9ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1c28f56083441dd83537a2df1765028",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ecc19b056fe344f8af40d121221add46",
              "IPY_MODEL_3295e0c1c8164c6e93e585ba6da58b01"
            ]
          }
        },
        "d1c28f56083441dd83537a2df1765028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecc19b056fe344f8af40d121221add46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3c70a7efc4c84b6b8a0ac328eaf4814f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef29926b269c4618b1ee76996c0aa286"
          }
        },
        "3295e0c1c8164c6e93e585ba6da58b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d342ba0f6614ff1b43357389a6adc6f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:31&lt;00:00, 43.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5161118833c64ad597101f36012496da"
          }
        },
        "3c70a7efc4c84b6b8a0ac328eaf4814f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef29926b269c4618b1ee76996c0aa286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d342ba0f6614ff1b43357389a6adc6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5161118833c64ad597101f36012496da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2180cfa204d6462fb4ef173ee1569583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8374000e58d04487b17924031865fec0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c11bf9a9f304e8a8ab37b5cdc17606a",
              "IPY_MODEL_629a3689155e43c2bf3ba8d34414dc89"
            ]
          }
        },
        "8374000e58d04487b17924031865fec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c11bf9a9f304e8a8ab37b5cdc17606a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_281c31359f3e406ea63658f2ee919491",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ef20f3d38f44a19aba6373d4aa2e9a1"
          }
        },
        "629a3689155e43c2bf3ba8d34414dc89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_152c4465e771493794c70478eccbf692",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:24&lt;00:00, 20.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_629a44e613c147b0a2513eaf760cb28d"
          }
        },
        "281c31359f3e406ea63658f2ee919491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ef20f3d38f44a19aba6373d4aa2e9a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "152c4465e771493794c70478eccbf692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "629a44e613c147b0a2513eaf760cb28d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH7HUhUiuGt4",
        "outputId": "b7b10578-3209-4f63-eb00-ce75cf6f34ca"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.0-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 9.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 65.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 67.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 30.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9AZmPBaeAEd"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoConfig\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import gc\n",
        "gc.enable()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdzSv2_sJW7M"
      },
      "source": [
        "NUM_FOLDS = 5\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 248\n",
        "EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
        "ROBERTA_PATH = \"roberta-base\"\n",
        "TOKENIZER_PATH = \"roberta-base\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLOrS47KJW95"
      },
      "source": [
        "def set_random_seed(random_seed):\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
        "\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "Bm0OZMDyJXAH",
        "outputId": "4de06467-3bce-4797-9956-490f10c44cc8"
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "submission_df = pd.read_csv(\"sample_submission.csv\")\n",
        "print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2834, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>target</th>\n",
              "      <th>standard_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c12129c31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When the young people returned to the ballroom...</td>\n",
              "      <td>-0.340259</td>\n",
              "      <td>0.464009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85aa80a4c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
              "      <td>-0.315372</td>\n",
              "      <td>0.480805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b69ac6792</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>As Roger had predicted, the snow departed as q...</td>\n",
              "      <td>-0.580118</td>\n",
              "      <td>0.476676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dd1000b26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>And outside before the palace a great garden w...</td>\n",
              "      <td>-1.054013</td>\n",
              "      <td>0.450007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37c1b32fb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Once upon a time there were Three Bears who li...</td>\n",
              "      <td>0.247197</td>\n",
              "      <td>0.510845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id url_legal  ...    target standard_error\n",
              "0  c12129c31       NaN  ... -0.340259       0.464009\n",
              "1  85aa80a4c       NaN  ... -0.315372       0.480805\n",
              "2  b69ac6792       NaN  ... -0.580118       0.476676\n",
              "3  dd1000b26       NaN  ... -1.054013       0.450007\n",
              "4  37c1b32fb       NaN  ...  0.247197       0.510845\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "1quLQGZjJXCY",
        "outputId": "9c59c322-214e-4521-8e51-d16196698106"
      },
      "source": [
        "# Remove incomplete entries if any.\n",
        "train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n",
        "              inplace=True)\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2833, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>target</th>\n",
              "      <th>standard_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c12129c31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When the young people returned to the ballroom...</td>\n",
              "      <td>-0.340259</td>\n",
              "      <td>0.464009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85aa80a4c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
              "      <td>-0.315372</td>\n",
              "      <td>0.480805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b69ac6792</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>As Roger had predicted, the snow departed as q...</td>\n",
              "      <td>-0.580118</td>\n",
              "      <td>0.476676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dd1000b26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>And outside before the palace a great garden w...</td>\n",
              "      <td>-1.054013</td>\n",
              "      <td>0.450007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37c1b32fb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Once upon a time there were Three Bears who li...</td>\n",
              "      <td>0.247197</td>\n",
              "      <td>0.510845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id url_legal  ...    target standard_error\n",
              "0  c12129c31       NaN  ... -0.340259       0.464009\n",
              "1  85aa80a4c       NaN  ... -0.315372       0.480805\n",
              "2  b69ac6792       NaN  ... -0.580118       0.476676\n",
              "3  dd1000b26       NaN  ... -1.054013       0.450007\n",
              "4  37c1b32fb       NaN  ...  0.247197       0.510845\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "4883ef61dca94192926fda155531384f",
            "7ee97af8324b4aeead9425915cdb95f2",
            "20a1a9bca5fd430c8cfeaefd9bbeb4e2",
            "2e3fc8dfcd0b41cc81120db9b6f382e6",
            "698a826abad94976af0bcb5508f5ee84",
            "ef13a8b475004f4e9b3f7b17538996de",
            "653952e5ecdc44eebdd31699725b2058",
            "3286934fed1f4de8b506da1097516a62",
            "fa386be406d1470f900dc11ad39a63d4",
            "1a54f9ddf89247628ee6e3ea024b0c39",
            "a2069eb8954e4154b1dd95d8740bab27",
            "b7f629b965004428b1f989ae45b0f019",
            "d793212ba9e1476c850c6a6ab0de6970",
            "2f3e8e0f01aa4fe990b40e2ade6459e2",
            "07f9b1a3d6e54b85b04240be5c4c0552",
            "8d69edb3c35a4f368a6e52b71a66266f",
            "4fc814ebcc694152be2510715788870d",
            "f90c2d2201f843f7a0943a231a34047a",
            "4bc3c3098511403bab8e21ff6227ae93",
            "1f99eb55f66a43678cf826920efa2f6d",
            "aade9d3503fb4b4a84d68ad4812cba0f",
            "c5442caf9ba74dddbc4768d6dc4aa143",
            "78113652540e4e9290e6eed4d7f7ce45",
            "c28909eec8b74b3587dfe68f5dc05736",
            "8a6abe73d45f4cf39f341e1a621c9ba8",
            "d1c28f56083441dd83537a2df1765028",
            "ecc19b056fe344f8af40d121221add46",
            "3295e0c1c8164c6e93e585ba6da58b01",
            "3c70a7efc4c84b6b8a0ac328eaf4814f",
            "ef29926b269c4618b1ee76996c0aa286",
            "1d342ba0f6614ff1b43357389a6adc6f",
            "5161118833c64ad597101f36012496da"
          ]
        },
        "id": "falJfT1vJXEW",
        "outputId": "f00d1290-9156-4d4d-9f89-6cb497766153"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4883ef61dca94192926fda155531384f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa386be406d1470f900dc11ad39a63d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fc814ebcc694152be2510715788870d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a6abe73d45f4cf39f341e1a621c9ba8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp4wo-l8JXGb"
      },
      "source": [
        "class LitDataset(Dataset):\n",
        "    def __init__(self, df, inference_only=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.df = df        \n",
        "        self.inference_only = inference_only\n",
        "        self.text = df.excerpt.tolist()\n",
        "        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
        "        \n",
        "        if not self.inference_only:\n",
        "            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
        "    \n",
        "        self.encoded = tokenizer.batch_encode_plus(\n",
        "            self.text,\n",
        "            padding = 'max_length',            \n",
        "            max_length = MAX_LEN,\n",
        "            truncation = True,\n",
        "            return_attention_mask=True\n",
        "        )        \n",
        " \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):        \n",
        "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
        "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
        "        \n",
        "        if self.inference_only:\n",
        "            return (input_ids, attention_mask)            \n",
        "        else:\n",
        "            target = self.target[index]\n",
        "            return (input_ids, attention_mask, target)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGGOAeu6JXIf"
      },
      "source": [
        "class LitModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n",
        "        config.update({\"output_hidden_states\":True, \n",
        "                       \"hidden_dropout_prob\": 0.0,\n",
        "                       \"layer_norm_eps\": 1e-7})                       \n",
        "        \n",
        "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
        "            \n",
        "        self.attention = nn.Sequential(            \n",
        "            nn.Linear(768, 512),            \n",
        "            nn.Tanh(),                       \n",
        "            nn.Linear(512, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )        \n",
        "\n",
        "        self.regressor = nn.Sequential(                        \n",
        "            nn.Linear(768, 1)                        \n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        roberta_output = self.roberta(input_ids=input_ids,\n",
        "                                      attention_mask=attention_mask)        \n",
        "\n",
        "        # There are a total of 13 layers of hidden states.\n",
        "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
        "        # We take the hidden states from the last Roberta layer.\n",
        "        last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
        "\n",
        "        # The number of cells is MAX_LEN.\n",
        "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
        "        # In order to condense hidden states of all cells to a context vector,\n",
        "        # we compute a weighted average of the hidden states of all cells.\n",
        "        # We compute the weight of each cell, using the attention neural network.\n",
        "        weights = self.attention(last_layer_hidden_states)\n",
        "                \n",
        "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
        "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
        "        # Now we compute context_vector as the weighted average.\n",
        "        # context_vector.shape is BATCH_SIZE x 768\n",
        "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
        "        \n",
        "        # Now we reduce the context vector to the prediction score.\n",
        "        return self.regressor(context_vector)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwvrCPEvJXKo"
      },
      "source": [
        "def eval_mse(model, data_loader):\n",
        "    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n",
        "    model.eval()            \n",
        "    mse_sum = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n",
        "            input_ids = input_ids.to(DEVICE)\n",
        "            attention_mask = attention_mask.to(DEVICE)                        \n",
        "            target = target.to(DEVICE)           \n",
        "            \n",
        "            pred = model(input_ids, attention_mask)                       \n",
        "\n",
        "            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n",
        "                \n",
        "\n",
        "    return mse_sum / len(data_loader.dataset)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv_tuhzNJXMz"
      },
      "source": [
        "def predict(model, data_loader):\n",
        "    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    result = np.zeros(len(data_loader.dataset))    \n",
        "    index = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
        "            input_ids = input_ids.to(DEVICE)\n",
        "            attention_mask = attention_mask.to(DEVICE)\n",
        "                        \n",
        "            pred = model(input_ids, attention_mask)                        \n",
        "\n",
        "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
        "            index += pred.shape[0]\n",
        "\n",
        "    return result"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Om0_lqKDoV"
      },
      "source": [
        "def train(model, model_path, train_loader, val_loader,\n",
        "          optimizer, scheduler=None, num_epochs=NUM_EPOCHS):    \n",
        "    best_val_rmse = None\n",
        "    best_epoch = 0\n",
        "    step = 0\n",
        "    last_eval_step = 0\n",
        "    eval_period = EVAL_SCHEDULE[0][1]    \n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):                           \n",
        "        val_rmse = None         \n",
        "\n",
        "        for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n",
        "            input_ids = input_ids.to(DEVICE)\n",
        "            attention_mask = attention_mask.to(DEVICE)            \n",
        "            target = target.to(DEVICE)                        \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "            pred = model(input_ids, attention_mask)\n",
        "                                                        \n",
        "            mse = nn.MSELoss(reduction=\"mean\")(pred.flatten(), target)\n",
        "                        \n",
        "            mse.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            if scheduler:\n",
        "                scheduler.step()\n",
        "            \n",
        "            if step >= last_eval_step + eval_period:\n",
        "                # Evaluate the model on val_loader.\n",
        "                elapsed_seconds = time.time() - start\n",
        "                num_steps = step - last_eval_step\n",
        "                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n",
        "                last_eval_step = step\n",
        "                \n",
        "                val_rmse = math.sqrt(eval_mse(model, val_loader))                            \n",
        "\n",
        "                print(f\"Epoch: {epoch} batch_num: {batch_num}\", \n",
        "                      f\"val_rmse: {val_rmse:0.4}\")\n",
        "\n",
        "                for rmse, period in EVAL_SCHEDULE:\n",
        "                    if val_rmse >= rmse:\n",
        "                        eval_period = period\n",
        "                        break                               \n",
        "                \n",
        "                if not best_val_rmse or val_rmse < best_val_rmse:                    \n",
        "                    best_val_rmse = val_rmse\n",
        "                    best_epoch = epoch\n",
        "                    torch.save(model.state_dict(), model_path)\n",
        "                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n",
        "                else:       \n",
        "                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n",
        "                          f\"(from epoch {best_epoch})\")                                    \n",
        "                    \n",
        "                start = time.time()\n",
        "                                            \n",
        "            step += 1\n",
        "                        \n",
        "    \n",
        "    return best_val_rmse"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU_HbFebKDmG"
      },
      "source": [
        "def create_optimizer(model):\n",
        "    named_parameters = list(model.named_parameters())    \n",
        "    \n",
        "    roberta_parameters = named_parameters[:197]    \n",
        "    attention_parameters = named_parameters[199:203]\n",
        "    regressor_parameters = named_parameters[203:]\n",
        "        \n",
        "    attention_group = [params for (name, params) in attention_parameters]\n",
        "    regressor_group = [params for (name, params) in regressor_parameters]\n",
        "\n",
        "    parameters = []\n",
        "    parameters.append({\"params\": attention_group})\n",
        "    parameters.append({\"params\": regressor_group})\n",
        "\n",
        "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
        "        weight_decay = 0.0 if \"bias\" in name else 0.01\n",
        "\n",
        "        lr = 2e-5\n",
        "\n",
        "        if layer_num >= 69:        \n",
        "            lr = 5e-5\n",
        "\n",
        "        if layer_num >= 133:\n",
        "            lr = 1e-4\n",
        "\n",
        "        parameters.append({\"params\": params,\n",
        "                           \"weight_decay\": weight_decay,\n",
        "                           \"lr\": lr})\n",
        "\n",
        "    return AdamW(parameters)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2180cfa204d6462fb4ef173ee1569583",
            "8374000e58d04487b17924031865fec0",
            "3c11bf9a9f304e8a8ab37b5cdc17606a",
            "629a3689155e43c2bf3ba8d34414dc89",
            "281c31359f3e406ea63658f2ee919491",
            "2ef20f3d38f44a19aba6373d4aa2e9a1",
            "152c4465e771493794c70478eccbf692",
            "629a44e613c147b0a2513eaf760cb28d"
          ]
        },
        "id": "uWmiXP2vKDgg",
        "outputId": "ee4a625a-837b-4efa-adce-c82bafee7f70"
      },
      "source": [
        "gc.collect()\n",
        "\n",
        "SEED = 1000\n",
        "list_val_rmse = []\n",
        "\n",
        "kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
        "\n",
        "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n",
        "    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n",
        "    model_path = f\"model_{fold + 1}.pth\"\n",
        "        \n",
        "    set_random_seed(SEED + fold)\n",
        "    \n",
        "    train_dataset = LitDataset(train_df.loc[train_indices])    \n",
        "    val_dataset = LitDataset(train_df.loc[val_indices])    \n",
        "        \n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                              drop_last=True, shuffle=True, num_workers=2)    \n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                            drop_last=False, shuffle=False, num_workers=2)    \n",
        "        \n",
        "    set_random_seed(SEED + fold)    \n",
        "    \n",
        "    model = LitModel().to(DEVICE)\n",
        "    \n",
        "    optimizer = create_optimizer(model)                        \n",
        "    scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_training_steps=NUM_EPOCHS * len(train_loader),\n",
        "        num_warmup_steps=50)    \n",
        "    \n",
        "    list_val_rmse.append(train(model, model_path, train_loader,\n",
        "                               val_loader, optimizer, scheduler=scheduler))\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "    \n",
        "    print(\"\\nPerformance estimates:\")\n",
        "    print(list_val_rmse)\n",
        "    print(\"Mean:\", np.array(list_val_rmse).mean())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2180cfa204d6462fb4ef173ee1569583",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 11.6 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.9376\n",
            "New best_val_rmse: 0.9376\n",
            "\n",
            "16 steps took 10.9 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.8588\n",
            "New best_val_rmse: 0.8588\n",
            "\n",
            "16 steps took 11.4 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.6361\n",
            "New best_val_rmse: 0.6361\n",
            "\n",
            "16 steps took 11.9 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.5997\n",
            "New best_val_rmse: 0.5997\n",
            "\n",
            "16 steps took 12.4 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.5737\n",
            "New best_val_rmse: 0.5737\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.5384\n",
            "New best_val_rmse: 0.5384\n",
            "\n",
            "16 steps took 11.8 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.5451\n",
            "Still best_val_rmse: 0.5384 (from epoch 0)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.5331\n",
            "New best_val_rmse: 0.5331\n",
            "\n",
            "16 steps took 12.2 seconds\n",
            "Epoch: 1 batch_num: 3 val_rmse: 0.5218\n",
            "New best_val_rmse: 0.5218\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 19 val_rmse: 0.5049\n",
            "New best_val_rmse: 0.5049\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 35 val_rmse: 0.5325\n",
            "Still best_val_rmse: 0.5049 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 51 val_rmse: 0.5322\n",
            "Still best_val_rmse: 0.5049 (from epoch 1)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 1 batch_num: 67 val_rmse: 0.5156\n",
            "Still best_val_rmse: 0.5049 (from epoch 1)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 1 batch_num: 83 val_rmse: 0.5069\n",
            "Still best_val_rmse: 0.5049 (from epoch 1)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 1 batch_num: 99 val_rmse: 0.4961\n",
            "New best_val_rmse: 0.4961\n",
            "\n",
            "8 steps took 5.97 seconds\n",
            "Epoch: 1 batch_num: 107 val_rmse: 0.4953\n",
            "New best_val_rmse: 0.4953\n",
            "\n",
            "8 steps took 5.97 seconds\n",
            "Epoch: 1 batch_num: 115 val_rmse: 0.5037\n",
            "Still best_val_rmse: 0.4953 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 131 val_rmse: 0.4904\n",
            "New best_val_rmse: 0.4904\n",
            "\n",
            "8 steps took 6.09 seconds\n",
            "Epoch: 1 batch_num: 139 val_rmse: 0.4863\n",
            "New best_val_rmse: 0.4863\n",
            "\n",
            "4 steps took 3.12 seconds\n",
            "Epoch: 2 batch_num: 2 val_rmse: 0.4868\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.01 seconds\n",
            "Epoch: 2 batch_num: 6 val_rmse: 0.4931\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "8 steps took 6.05 seconds\n",
            "Epoch: 2 batch_num: 14 val_rmse: 0.4929\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "8 steps took 6.02 seconds\n",
            "Epoch: 2 batch_num: 22 val_rmse: 0.5267\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 2 batch_num: 38 val_rmse: 0.5077\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 2 batch_num: 54 val_rmse: 0.4977\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "8 steps took 6.0 seconds\n",
            "Epoch: 2 batch_num: 62 val_rmse: 0.489\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 66 val_rmse: 0.4865\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 70 val_rmse: 0.4876\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 74 val_rmse: 0.4869\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 2.99 seconds\n",
            "Epoch: 2 batch_num: 78 val_rmse: 0.4903\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "8 steps took 6.0 seconds\n",
            "Epoch: 2 batch_num: 86 val_rmse: 0.505\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 2 batch_num: 102 val_rmse: 0.4905\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "8 steps took 6.01 seconds\n",
            "Epoch: 2 batch_num: 110 val_rmse: 0.4878\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 114 val_rmse: 0.4878\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 118 val_rmse: 0.4881\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 122 val_rmse: 0.4882\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.01 seconds\n",
            "Epoch: 2 batch_num: 126 val_rmse: 0.4882\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.01 seconds\n",
            "Epoch: 2 batch_num: 130 val_rmse: 0.4882\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 134 val_rmse: 0.4883\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 138 val_rmse: 0.4884\n",
            "Still best_val_rmse: 0.4863 (from epoch 1)\n",
            "\n",
            "Performance estimates:\n",
            "[0.48626735580995334]\n",
            "Mean: 0.48626735580995334\n",
            "\n",
            "Fold 2/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 12.6 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.9604\n",
            "New best_val_rmse: 0.9604\n",
            "\n",
            "16 steps took 12.6 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.7368\n",
            "New best_val_rmse: 0.7368\n",
            "\n",
            "16 steps took 12.2 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.7033\n",
            "New best_val_rmse: 0.7033\n",
            "\n",
            "16 steps took 11.8 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6518\n",
            "New best_val_rmse: 0.6518\n",
            "\n",
            "16 steps took 11.9 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.6198\n",
            "New best_val_rmse: 0.6198\n",
            "\n",
            "16 steps took 12.2 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.6564\n",
            "Still best_val_rmse: 0.6198 (from epoch 0)\n",
            "\n",
            "16 steps took 12.2 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.5728\n",
            "New best_val_rmse: 0.5728\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.5464\n",
            "New best_val_rmse: 0.5464\n",
            "\n",
            "16 steps took 12.2 seconds\n",
            "Epoch: 1 batch_num: 3 val_rmse: 0.5299\n",
            "New best_val_rmse: 0.5299\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 1 batch_num: 19 val_rmse: 0.5204\n",
            "New best_val_rmse: 0.5204\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 1 batch_num: 35 val_rmse: 0.503\n",
            "New best_val_rmse: 0.503\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 51 val_rmse: 0.5023\n",
            "New best_val_rmse: 0.5023\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 67 val_rmse: 0.5147\n",
            "Still best_val_rmse: 0.5023 (from epoch 1)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 1 batch_num: 83 val_rmse: 0.4962\n",
            "New best_val_rmse: 0.4962\n",
            "\n",
            "8 steps took 6.01 seconds\n",
            "Epoch: 1 batch_num: 91 val_rmse: 0.4898\n",
            "New best_val_rmse: 0.4898\n",
            "\n",
            "4 steps took 2.99 seconds\n",
            "Epoch: 1 batch_num: 95 val_rmse: 0.4923\n",
            "Still best_val_rmse: 0.4898 (from epoch 1)\n",
            "\n",
            "8 steps took 6.03 seconds\n",
            "Epoch: 1 batch_num: 103 val_rmse: 0.4817\n",
            "New best_val_rmse: 0.4817\n",
            "\n",
            "4 steps took 3.01 seconds\n",
            "Epoch: 1 batch_num: 107 val_rmse: 0.4772\n",
            "New best_val_rmse: 0.4772\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 1 batch_num: 109 val_rmse: 0.4823\n",
            "Still best_val_rmse: 0.4772 (from epoch 1)\n",
            "\n",
            "4 steps took 3.02 seconds\n",
            "Epoch: 1 batch_num: 113 val_rmse: 0.5005\n",
            "Still best_val_rmse: 0.4772 (from epoch 1)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 1 batch_num: 129 val_rmse: 0.47\n",
            "New best_val_rmse: 0.47\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 1 batch_num: 131 val_rmse: 0.4785\n",
            "Still best_val_rmse: 0.47 (from epoch 1)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 1 batch_num: 133 val_rmse: 0.4762\n",
            "Still best_val_rmse: 0.47 (from epoch 1)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 1 batch_num: 135 val_rmse: 0.4776\n",
            "Still best_val_rmse: 0.47 (from epoch 1)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 1 batch_num: 137 val_rmse: 0.4867\n",
            "Still best_val_rmse: 0.47 (from epoch 1)\n",
            "\n",
            "4 steps took 3.13 seconds\n",
            "Epoch: 2 batch_num: 0 val_rmse: 0.4791\n",
            "Still best_val_rmse: 0.47 (from epoch 1)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 2 val_rmse: 0.4691\n",
            "New best_val_rmse: 0.4691\n",
            "\n",
            "1 steps took 0.703 seconds\n",
            "Epoch: 2 batch_num: 3 val_rmse: 0.469\n",
            "New best_val_rmse: 0.469\n",
            "\n",
            "1 steps took 0.7 seconds\n",
            "Epoch: 2 batch_num: 4 val_rmse: 0.4722\n",
            "Still best_val_rmse: 0.469 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 6 val_rmse: 0.4713\n",
            "Still best_val_rmse: 0.469 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 8 val_rmse: 0.4691\n",
            "Still best_val_rmse: 0.469 (from epoch 2)\n",
            "\n",
            "1 steps took 0.727 seconds\n",
            "Epoch: 2 batch_num: 9 val_rmse: 0.4678\n",
            "New best_val_rmse: 0.4678\n",
            "\n",
            "1 steps took 0.703 seconds\n",
            "Epoch: 2 batch_num: 10 val_rmse: 0.4673\n",
            "New best_val_rmse: 0.4673\n",
            "\n",
            "1 steps took 0.707 seconds\n",
            "Epoch: 2 batch_num: 11 val_rmse: 0.4681\n",
            "Still best_val_rmse: 0.4673 (from epoch 2)\n",
            "\n",
            "1 steps took 0.726 seconds\n",
            "Epoch: 2 batch_num: 12 val_rmse: 0.4718\n",
            "Still best_val_rmse: 0.4673 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 14 val_rmse: 0.482\n",
            "Still best_val_rmse: 0.4673 (from epoch 2)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 18 val_rmse: 0.4694\n",
            "Still best_val_rmse: 0.4673 (from epoch 2)\n",
            "\n",
            "1 steps took 0.718 seconds\n",
            "Epoch: 2 batch_num: 19 val_rmse: 0.466\n",
            "New best_val_rmse: 0.466\n",
            "\n",
            "1 steps took 0.703 seconds\n",
            "Epoch: 2 batch_num: 20 val_rmse: 0.4667\n",
            "Still best_val_rmse: 0.466 (from epoch 2)\n",
            "\n",
            "1 steps took 0.719 seconds\n",
            "Epoch: 2 batch_num: 21 val_rmse: 0.4683\n",
            "Still best_val_rmse: 0.466 (from epoch 2)\n",
            "\n",
            "1 steps took 0.719 seconds\n",
            "Epoch: 2 batch_num: 22 val_rmse: 0.4699\n",
            "Still best_val_rmse: 0.466 (from epoch 2)\n",
            "\n",
            "1 steps took 0.724 seconds\n",
            "Epoch: 2 batch_num: 23 val_rmse: 0.4704\n",
            "Still best_val_rmse: 0.466 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 25 val_rmse: 0.4677\n",
            "Still best_val_rmse: 0.466 (from epoch 2)\n",
            "\n",
            "1 steps took 0.718 seconds\n",
            "Epoch: 2 batch_num: 26 val_rmse: 0.4646\n",
            "New best_val_rmse: 0.4646\n",
            "\n",
            "1 steps took 0.71 seconds\n",
            "Epoch: 2 batch_num: 27 val_rmse: 0.4636\n",
            "New best_val_rmse: 0.4636\n",
            "\n",
            "1 steps took 0.707 seconds\n",
            "Epoch: 2 batch_num: 28 val_rmse: 0.4652\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "1 steps took 0.715 seconds\n",
            "Epoch: 2 batch_num: 29 val_rmse: 0.4712\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 31 val_rmse: 0.488\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "4 steps took 3.02 seconds\n",
            "Epoch: 2 batch_num: 35 val_rmse: 0.4908\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "8 steps took 6.0 seconds\n",
            "Epoch: 2 batch_num: 43 val_rmse: 0.4787\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 45 val_rmse: 0.4769\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 47 val_rmse: 0.4676\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "1 steps took 0.708 seconds\n",
            "Epoch: 2 batch_num: 48 val_rmse: 0.4678\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "1 steps took 0.714 seconds\n",
            "Epoch: 2 batch_num: 49 val_rmse: 0.4745\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 51 val_rmse: 0.4973\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "8 steps took 5.96 seconds\n",
            "Epoch: 2 batch_num: 59 val_rmse: 0.4652\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "1 steps took 0.71 seconds\n",
            "Epoch: 2 batch_num: 60 val_rmse: 0.4647\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "1 steps took 0.708 seconds\n",
            "Epoch: 2 batch_num: 61 val_rmse: 0.4658\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "1 steps took 0.724 seconds\n",
            "Epoch: 2 batch_num: 62 val_rmse: 0.4665\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "1 steps took 0.718 seconds\n",
            "Epoch: 2 batch_num: 63 val_rmse: 0.4662\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "1 steps took 0.722 seconds\n",
            "Epoch: 2 batch_num: 64 val_rmse: 0.465\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "1 steps took 0.716 seconds\n",
            "Epoch: 2 batch_num: 65 val_rmse: 0.464\n",
            "Still best_val_rmse: 0.4636 (from epoch 2)\n",
            "\n",
            "1 steps took 0.721 seconds\n",
            "Epoch: 2 batch_num: 66 val_rmse: 0.4634\n",
            "New best_val_rmse: 0.4634\n",
            "\n",
            "1 steps took 0.722 seconds\n",
            "Epoch: 2 batch_num: 67 val_rmse: 0.4634\n",
            "New best_val_rmse: 0.4634\n",
            "\n",
            "1 steps took 0.708 seconds\n",
            "Epoch: 2 batch_num: 68 val_rmse: 0.4642\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.713 seconds\n",
            "Epoch: 2 batch_num: 69 val_rmse: 0.4659\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.721 seconds\n",
            "Epoch: 2 batch_num: 70 val_rmse: 0.4673\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.731 seconds\n",
            "Epoch: 2 batch_num: 71 val_rmse: 0.4699\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.716 seconds\n",
            "Epoch: 2 batch_num: 72 val_rmse: 0.4716\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 74 val_rmse: 0.4718\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 76 val_rmse: 0.4693\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.711 seconds\n",
            "Epoch: 2 batch_num: 77 val_rmse: 0.468\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.723 seconds\n",
            "Epoch: 2 batch_num: 78 val_rmse: 0.4662\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.722 seconds\n",
            "Epoch: 2 batch_num: 79 val_rmse: 0.4651\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.722 seconds\n",
            "Epoch: 2 batch_num: 80 val_rmse: 0.4646\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.72 seconds\n",
            "Epoch: 2 batch_num: 81 val_rmse: 0.4646\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.716 seconds\n",
            "Epoch: 2 batch_num: 82 val_rmse: 0.4646\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.715 seconds\n",
            "Epoch: 2 batch_num: 83 val_rmse: 0.4646\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.723 seconds\n",
            "Epoch: 2 batch_num: 84 val_rmse: 0.4647\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.709 seconds\n",
            "Epoch: 2 batch_num: 85 val_rmse: 0.4649\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.717 seconds\n",
            "Epoch: 2 batch_num: 86 val_rmse: 0.465\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.722 seconds\n",
            "Epoch: 2 batch_num: 87 val_rmse: 0.4652\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.716 seconds\n",
            "Epoch: 2 batch_num: 88 val_rmse: 0.4654\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.734 seconds\n",
            "Epoch: 2 batch_num: 89 val_rmse: 0.4657\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.721 seconds\n",
            "Epoch: 2 batch_num: 90 val_rmse: 0.466\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.723 seconds\n",
            "Epoch: 2 batch_num: 91 val_rmse: 0.4663\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.729 seconds\n",
            "Epoch: 2 batch_num: 92 val_rmse: 0.4667\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.718 seconds\n",
            "Epoch: 2 batch_num: 93 val_rmse: 0.4672\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.723 seconds\n",
            "Epoch: 2 batch_num: 94 val_rmse: 0.4679\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.714 seconds\n",
            "Epoch: 2 batch_num: 95 val_rmse: 0.469\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "1 steps took 0.713 seconds\n",
            "Epoch: 2 batch_num: 96 val_rmse: 0.4701\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 98 val_rmse: 0.4725\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 100 val_rmse: 0.474\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 102 val_rmse: 0.4742\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 104 val_rmse: 0.4737\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 106 val_rmse: 0.4738\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 108 val_rmse: 0.4738\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 110 val_rmse: 0.4734\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 112 val_rmse: 0.4728\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 114 val_rmse: 0.4724\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 116 val_rmse: 0.4719\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 118 val_rmse: 0.4717\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 120 val_rmse: 0.4713\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 122 val_rmse: 0.471\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 124 val_rmse: 0.4708\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 126 val_rmse: 0.4706\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 128 val_rmse: 0.4704\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 130 val_rmse: 0.4703\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 132 val_rmse: 0.4703\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 134 val_rmse: 0.4703\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 136 val_rmse: 0.4703\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 138 val_rmse: 0.4703\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 140 val_rmse: 0.4703\n",
            "Still best_val_rmse: 0.4634 (from epoch 2)\n",
            "\n",
            "Performance estimates:\n",
            "[0.48626735580995334, 0.4633791344726053]\n",
            "Mean: 0.4748232451412793\n",
            "\n",
            "Fold 3/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 12.7 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 1.022\n",
            "New best_val_rmse: 1.022\n",
            "\n",
            "16 steps took 12.4 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 1.05\n",
            "Still best_val_rmse: 1.022 (from epoch 0)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.6578\n",
            "New best_val_rmse: 0.6578\n",
            "\n",
            "16 steps took 11.8 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6271\n",
            "New best_val_rmse: 0.6271\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.639\n",
            "Still best_val_rmse: 0.6271 (from epoch 0)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.5895\n",
            "New best_val_rmse: 0.5895\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.533\n",
            "New best_val_rmse: 0.533\n",
            "\n",
            "16 steps took 11.9 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.5915\n",
            "Still best_val_rmse: 0.533 (from epoch 0)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 1 batch_num: 3 val_rmse: 0.5176\n",
            "New best_val_rmse: 0.5176\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 19 val_rmse: 0.553\n",
            "Still best_val_rmse: 0.5176 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 35 val_rmse: 0.5177\n",
            "Still best_val_rmse: 0.5176 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 51 val_rmse: 0.5196\n",
            "Still best_val_rmse: 0.5176 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 67 val_rmse: 0.5732\n",
            "Still best_val_rmse: 0.5176 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 83 val_rmse: 0.4982\n",
            "New best_val_rmse: 0.4982\n",
            "\n",
            "8 steps took 5.98 seconds\n",
            "Epoch: 1 batch_num: 91 val_rmse: 0.5012\n",
            "Still best_val_rmse: 0.4982 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 107 val_rmse: 0.4942\n",
            "New best_val_rmse: 0.4942\n",
            "\n",
            "8 steps took 5.96 seconds\n",
            "Epoch: 1 batch_num: 115 val_rmse: 0.4827\n",
            "New best_val_rmse: 0.4827\n",
            "\n",
            "4 steps took 2.97 seconds\n",
            "Epoch: 1 batch_num: 119 val_rmse: 0.4961\n",
            "Still best_val_rmse: 0.4827 (from epoch 1)\n",
            "\n",
            "8 steps took 6.0 seconds\n",
            "Epoch: 1 batch_num: 127 val_rmse: 0.4829\n",
            "Still best_val_rmse: 0.4827 (from epoch 1)\n",
            "\n",
            "4 steps took 3.01 seconds\n",
            "Epoch: 1 batch_num: 131 val_rmse: 0.5094\n",
            "Still best_val_rmse: 0.4827 (from epoch 1)\n",
            "\n",
            "16 steps took 12.2 seconds\n",
            "Epoch: 2 batch_num: 6 val_rmse: 0.4779\n",
            "New best_val_rmse: 0.4779\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 8 val_rmse: 0.4943\n",
            "Still best_val_rmse: 0.4779 (from epoch 2)\n",
            "\n",
            "8 steps took 5.95 seconds\n",
            "Epoch: 2 batch_num: 16 val_rmse: 0.4867\n",
            "Still best_val_rmse: 0.4779 (from epoch 2)\n",
            "\n",
            "4 steps took 2.97 seconds\n",
            "Epoch: 2 batch_num: 20 val_rmse: 0.4758\n",
            "New best_val_rmse: 0.4758\n",
            "\n",
            "2 steps took 1.45 seconds\n",
            "Epoch: 2 batch_num: 22 val_rmse: 0.4771\n",
            "Still best_val_rmse: 0.4758 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 24 val_rmse: 0.4889\n",
            "Still best_val_rmse: 0.4758 (from epoch 2)\n",
            "\n",
            "4 steps took 2.99 seconds\n",
            "Epoch: 2 batch_num: 28 val_rmse: 0.4852\n",
            "Still best_val_rmse: 0.4758 (from epoch 2)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 32 val_rmse: 0.4903\n",
            "Still best_val_rmse: 0.4758 (from epoch 2)\n",
            "\n",
            "8 steps took 6.01 seconds\n",
            "Epoch: 2 batch_num: 40 val_rmse: 0.4934\n",
            "Still best_val_rmse: 0.4758 (from epoch 2)\n",
            "\n",
            "8 steps took 6.02 seconds\n",
            "Epoch: 2 batch_num: 48 val_rmse: 0.4766\n",
            "Still best_val_rmse: 0.4758 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 50 val_rmse: 0.479\n",
            "Still best_val_rmse: 0.4758 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 52 val_rmse: 0.4783\n",
            "Still best_val_rmse: 0.4758 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 54 val_rmse: 0.4765\n",
            "Still best_val_rmse: 0.4758 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 56 val_rmse: 0.4757\n",
            "New best_val_rmse: 0.4757\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 58 val_rmse: 0.4762\n",
            "Still best_val_rmse: 0.4757 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 60 val_rmse: 0.4774\n",
            "Still best_val_rmse: 0.4757 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 62 val_rmse: 0.4806\n",
            "Still best_val_rmse: 0.4757 (from epoch 2)\n",
            "\n",
            "4 steps took 2.99 seconds\n",
            "Epoch: 2 batch_num: 66 val_rmse: 0.4772\n",
            "Still best_val_rmse: 0.4757 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 68 val_rmse: 0.4761\n",
            "Still best_val_rmse: 0.4757 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 70 val_rmse: 0.4752\n",
            "New best_val_rmse: 0.4752\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 72 val_rmse: 0.4743\n",
            "New best_val_rmse: 0.4743\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 74 val_rmse: 0.4737\n",
            "New best_val_rmse: 0.4737\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 76 val_rmse: 0.473\n",
            "New best_val_rmse: 0.473\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 78 val_rmse: 0.4728\n",
            "New best_val_rmse: 0.4728\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 80 val_rmse: 0.473\n",
            "Still best_val_rmse: 0.4728 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 82 val_rmse: 0.4738\n",
            "Still best_val_rmse: 0.4728 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 84 val_rmse: 0.475\n",
            "Still best_val_rmse: 0.4728 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 86 val_rmse: 0.4754\n",
            "Still best_val_rmse: 0.4728 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 88 val_rmse: 0.4767\n",
            "Still best_val_rmse: 0.4728 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 90 val_rmse: 0.4756\n",
            "Still best_val_rmse: 0.4728 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 92 val_rmse: 0.475\n",
            "Still best_val_rmse: 0.4728 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 94 val_rmse: 0.474\n",
            "Still best_val_rmse: 0.4728 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 96 val_rmse: 0.4732\n",
            "Still best_val_rmse: 0.4728 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 98 val_rmse: 0.4725\n",
            "New best_val_rmse: 0.4725\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 100 val_rmse: 0.472\n",
            "New best_val_rmse: 0.472\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 102 val_rmse: 0.4716\n",
            "New best_val_rmse: 0.4716\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 104 val_rmse: 0.4715\n",
            "New best_val_rmse: 0.4715\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 106 val_rmse: 0.4715\n",
            "New best_val_rmse: 0.4715\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 108 val_rmse: 0.4716\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 110 val_rmse: 0.4718\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 112 val_rmse: 0.4719\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 114 val_rmse: 0.4721\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 116 val_rmse: 0.4724\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 118 val_rmse: 0.4726\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 120 val_rmse: 0.4727\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.45 seconds\n",
            "Epoch: 2 batch_num: 122 val_rmse: 0.4727\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 124 val_rmse: 0.4725\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 126 val_rmse: 0.4725\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 128 val_rmse: 0.4725\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 130 val_rmse: 0.4724\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 132 val_rmse: 0.4724\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 134 val_rmse: 0.4724\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 136 val_rmse: 0.4724\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 138 val_rmse: 0.4724\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 140 val_rmse: 0.4724\n",
            "Still best_val_rmse: 0.4715 (from epoch 2)\n",
            "\n",
            "Performance estimates:\n",
            "[0.48626735580995334, 0.4633791344726053, 0.47152624702735746]\n",
            "Mean: 0.473724245769972\n",
            "\n",
            "Fold 4/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 12.8 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.9726\n",
            "New best_val_rmse: 0.9726\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.8741\n",
            "New best_val_rmse: 0.8741\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.8858\n",
            "Still best_val_rmse: 0.8741 (from epoch 0)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.7008\n",
            "New best_val_rmse: 0.7008\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.6233\n",
            "New best_val_rmse: 0.6233\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.6351\n",
            "Still best_val_rmse: 0.6233 (from epoch 0)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.5641\n",
            "New best_val_rmse: 0.5641\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.6171\n",
            "Still best_val_rmse: 0.5641 (from epoch 0)\n",
            "\n",
            "16 steps took 12.2 seconds\n",
            "Epoch: 1 batch_num: 3 val_rmse: 0.5369\n",
            "New best_val_rmse: 0.5369\n",
            "\n",
            "16 steps took 11.9 seconds\n",
            "Epoch: 1 batch_num: 19 val_rmse: 0.5449\n",
            "Still best_val_rmse: 0.5369 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 35 val_rmse: 0.542\n",
            "Still best_val_rmse: 0.5369 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 51 val_rmse: 0.5218\n",
            "New best_val_rmse: 0.5218\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 67 val_rmse: 0.5147\n",
            "New best_val_rmse: 0.5147\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 83 val_rmse: 0.5162\n",
            "Still best_val_rmse: 0.5147 (from epoch 1)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 1 batch_num: 99 val_rmse: 0.5091\n",
            "New best_val_rmse: 0.5091\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 115 val_rmse: 0.495\n",
            "New best_val_rmse: 0.495\n",
            "\n",
            "8 steps took 5.95 seconds\n",
            "Epoch: 1 batch_num: 123 val_rmse: 0.5014\n",
            "Still best_val_rmse: 0.495 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 139 val_rmse: 0.4996\n",
            "Still best_val_rmse: 0.495 (from epoch 1)\n",
            "\n",
            "8 steps took 6.16 seconds\n",
            "Epoch: 2 batch_num: 6 val_rmse: 0.4927\n",
            "New best_val_rmse: 0.4927\n",
            "\n",
            "8 steps took 5.99 seconds\n",
            "Epoch: 2 batch_num: 14 val_rmse: 0.4878\n",
            "New best_val_rmse: 0.4878\n",
            "\n",
            "4 steps took 2.99 seconds\n",
            "Epoch: 2 batch_num: 18 val_rmse: 0.4879\n",
            "Still best_val_rmse: 0.4878 (from epoch 2)\n",
            "\n",
            "4 steps took 2.99 seconds\n",
            "Epoch: 2 batch_num: 22 val_rmse: 0.4855\n",
            "New best_val_rmse: 0.4855\n",
            "\n",
            "4 steps took 2.98 seconds\n",
            "Epoch: 2 batch_num: 26 val_rmse: 0.4847\n",
            "New best_val_rmse: 0.4847\n",
            "\n",
            "4 steps took 2.98 seconds\n",
            "Epoch: 2 batch_num: 30 val_rmse: 0.5034\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 2 batch_num: 46 val_rmse: 0.4926\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "8 steps took 6.01 seconds\n",
            "Epoch: 2 batch_num: 54 val_rmse: 0.5122\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 2 batch_num: 70 val_rmse: 0.488\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "4 steps took 2.98 seconds\n",
            "Epoch: 2 batch_num: 74 val_rmse: 0.495\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "8 steps took 6.0 seconds\n",
            "Epoch: 2 batch_num: 82 val_rmse: 0.5157\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 2 batch_num: 98 val_rmse: 0.496\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "8 steps took 5.97 seconds\n",
            "Epoch: 2 batch_num: 106 val_rmse: 0.493\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "8 steps took 5.97 seconds\n",
            "Epoch: 2 batch_num: 114 val_rmse: 0.4924\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "8 steps took 5.99 seconds\n",
            "Epoch: 2 batch_num: 122 val_rmse: 0.4924\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "8 steps took 5.99 seconds\n",
            "Epoch: 2 batch_num: 130 val_rmse: 0.4924\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "8 steps took 6.0 seconds\n",
            "Epoch: 2 batch_num: 138 val_rmse: 0.4924\n",
            "Still best_val_rmse: 0.4847 (from epoch 2)\n",
            "\n",
            "Performance estimates:\n",
            "[0.48626735580995334, 0.4633791344726053, 0.47152624702735746, 0.48469677249911297]\n",
            "Mean: 0.47646737745225726\n",
            "\n",
            "Fold 5/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 12.8 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.9199\n",
            "New best_val_rmse: 0.9199\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.748\n",
            "New best_val_rmse: 0.748\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.6244\n",
            "New best_val_rmse: 0.6244\n",
            "\n",
            "16 steps took 11.9 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6198\n",
            "New best_val_rmse: 0.6198\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.5634\n",
            "New best_val_rmse: 0.5634\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.6375\n",
            "Still best_val_rmse: 0.5634 (from epoch 0)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.6047\n",
            "Still best_val_rmse: 0.5634 (from epoch 0)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.5513\n",
            "New best_val_rmse: 0.5513\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 1 batch_num: 3 val_rmse: 0.6348\n",
            "Still best_val_rmse: 0.5513 (from epoch 0)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 19 val_rmse: 0.555\n",
            "Still best_val_rmse: 0.5513 (from epoch 0)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 35 val_rmse: 0.5149\n",
            "New best_val_rmse: 0.5149\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 51 val_rmse: 0.5144\n",
            "New best_val_rmse: 0.5144\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 67 val_rmse: 0.5005\n",
            "New best_val_rmse: 0.5005\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 83 val_rmse: 0.537\n",
            "Still best_val_rmse: 0.5005 (from epoch 1)\n",
            "\n",
            "16 steps took 12.0 seconds\n",
            "Epoch: 1 batch_num: 99 val_rmse: 0.4932\n",
            "New best_val_rmse: 0.4932\n",
            "\n",
            "8 steps took 6.01 seconds\n",
            "Epoch: 1 batch_num: 107 val_rmse: 0.4985\n",
            "Still best_val_rmse: 0.4932 (from epoch 1)\n",
            "\n",
            "8 steps took 6.01 seconds\n",
            "Epoch: 1 batch_num: 115 val_rmse: 0.4868\n",
            "New best_val_rmse: 0.4868\n",
            "\n",
            "4 steps took 2.98 seconds\n",
            "Epoch: 1 batch_num: 119 val_rmse: 0.4913\n",
            "Still best_val_rmse: 0.4868 (from epoch 1)\n",
            "\n",
            "8 steps took 5.98 seconds\n",
            "Epoch: 1 batch_num: 127 val_rmse: 0.4968\n",
            "Still best_val_rmse: 0.4868 (from epoch 1)\n",
            "\n",
            "8 steps took 5.99 seconds\n",
            "Epoch: 1 batch_num: 135 val_rmse: 0.5076\n",
            "Still best_val_rmse: 0.4868 (from epoch 1)\n",
            "\n",
            "16 steps took 12.2 seconds\n",
            "Epoch: 2 batch_num: 10 val_rmse: 0.4923\n",
            "Still best_val_rmse: 0.4868 (from epoch 1)\n",
            "\n",
            "8 steps took 5.96 seconds\n",
            "Epoch: 2 batch_num: 18 val_rmse: 0.4768\n",
            "New best_val_rmse: 0.4768\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 20 val_rmse: 0.476\n",
            "New best_val_rmse: 0.476\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 22 val_rmse: 0.4773\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 24 val_rmse: 0.4847\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "4 steps took 3.01 seconds\n",
            "Epoch: 2 batch_num: 28 val_rmse: 0.5015\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "16 steps took 12.1 seconds\n",
            "Epoch: 2 batch_num: 44 val_rmse: 0.4765\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 46 val_rmse: 0.4768\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 48 val_rmse: 0.479\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 50 val_rmse: 0.4838\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "4 steps took 2.97 seconds\n",
            "Epoch: 2 batch_num: 54 val_rmse: 0.498\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "8 steps took 6.0 seconds\n",
            "Epoch: 2 batch_num: 62 val_rmse: 0.4823\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "4 steps took 2.99 seconds\n",
            "Epoch: 2 batch_num: 66 val_rmse: 0.4766\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 68 val_rmse: 0.4765\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 70 val_rmse: 0.4777\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 72 val_rmse: 0.4796\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 74 val_rmse: 0.4809\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "4 steps took 3.01 seconds\n",
            "Epoch: 2 batch_num: 78 val_rmse: 0.4799\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 80 val_rmse: 0.4819\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "4 steps took 3.01 seconds\n",
            "Epoch: 2 batch_num: 84 val_rmse: 0.4836\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "4 steps took 3.0 seconds\n",
            "Epoch: 2 batch_num: 88 val_rmse: 0.4802\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "4 steps took 2.99 seconds\n",
            "Epoch: 2 batch_num: 92 val_rmse: 0.4777\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 94 val_rmse: 0.4774\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 96 val_rmse: 0.4781\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 98 val_rmse: 0.4786\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 100 val_rmse: 0.4787\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 102 val_rmse: 0.4786\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 104 val_rmse: 0.4789\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 106 val_rmse: 0.4793\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 108 val_rmse: 0.4791\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 110 val_rmse: 0.4784\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 112 val_rmse: 0.4777\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 114 val_rmse: 0.4771\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 116 val_rmse: 0.4765\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 118 val_rmse: 0.4761\n",
            "Still best_val_rmse: 0.476 (from epoch 2)\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 120 val_rmse: 0.4758\n",
            "New best_val_rmse: 0.4758\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 122 val_rmse: 0.4755\n",
            "New best_val_rmse: 0.4755\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 124 val_rmse: 0.4755\n",
            "New best_val_rmse: 0.4755\n",
            "\n",
            "2 steps took 1.46 seconds\n",
            "Epoch: 2 batch_num: 126 val_rmse: 0.4754\n",
            "New best_val_rmse: 0.4754\n",
            "\n",
            "2 steps took 1.47 seconds\n",
            "Epoch: 2 batch_num: 128 val_rmse: 0.4754\n",
            "New best_val_rmse: 0.4754\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 130 val_rmse: 0.4753\n",
            "New best_val_rmse: 0.4753\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 132 val_rmse: 0.4753\n",
            "New best_val_rmse: 0.4753\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 134 val_rmse: 0.4753\n",
            "New best_val_rmse: 0.4753\n",
            "\n",
            "2 steps took 1.48 seconds\n",
            "Epoch: 2 batch_num: 136 val_rmse: 0.4753\n",
            "New best_val_rmse: 0.4753\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 138 val_rmse: 0.4753\n",
            "Still best_val_rmse: 0.4753 (from epoch 2)\n",
            "\n",
            "2 steps took 1.49 seconds\n",
            "Epoch: 2 batch_num: 140 val_rmse: 0.4753\n",
            "Still best_val_rmse: 0.4753 (from epoch 2)\n",
            "\n",
            "Performance estimates:\n",
            "[0.48626735580995334, 0.4633791344726053, 0.47152624702735746, 0.48469677249911297, 0.4753159294967402]\n",
            "Mean: 0.4762370878611538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0CmgUhWKDeb",
        "outputId": "76593786-f283-4f13-e74b-36607e8ce593"
      },
      "source": [
        "test_dataset = LitDataset(test_df, inference_only=True)\n",
        "\n",
        "all_predictions = np.zeros((len(list_val_rmse), len(test_df)))\n",
        "\n",
        "test_dataset = LitDataset(test_df, inference_only=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                         drop_last=False, shuffle=False, num_workers=2)\n",
        "\n",
        "for index in range(len(list_val_rmse)):            \n",
        "    model_path = f\"model_{index + 1}.pth\"\n",
        "    print(f\"\\nUsing {model_path}\")\n",
        "                        \n",
        "    model = LitModel()\n",
        "    model.load_state_dict(torch.load(model_path))    \n",
        "    model.to(DEVICE)\n",
        "    \n",
        "    all_predictions[index] = predict(model, test_loader)\n",
        "    \n",
        "    del model\n",
        "    gc.collect()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using model_1.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using model_2.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using model_3.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using model_4.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using model_5.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRHlNMX6KDcZ",
        "outputId": "5b6029f9-9e69-4467-c587-876697d4000a"
      },
      "source": [
        "predictions = all_predictions.mean(axis=0)\n",
        "submission_df.target = predictions\n",
        "print(submission_df)\n",
        "submission_df.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          id    target\n",
            "0  c0f722661 -0.497480\n",
            "1  f0953f0a5 -0.481881\n",
            "2  0df072751 -0.406824\n",
            "3  04caf4e0c -2.532548\n",
            "4  0e63f8bea -1.736274\n",
            "5  12537fe78 -1.477120\n",
            "6  965e592c0  0.178750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC4DaDpEKDaQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
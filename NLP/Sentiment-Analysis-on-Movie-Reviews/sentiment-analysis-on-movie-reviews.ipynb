{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e29538",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:05.745428Z",
     "iopub.status.busy": "2021-08-05T18:18:05.744710Z",
     "iopub.status.idle": "2021-08-05T18:18:08.519575Z",
     "shell.execute_reply": "2021-08-05T18:18:08.518444Z",
     "shell.execute_reply.started": "2021-08-05T17:47:44.859923Z"
    },
    "papermill": {
     "duration": 2.809223,
     "end_time": "2021-08-05T18:18:08.519816",
     "exception": false,
     "start_time": "2021-08-05T18:18:05.710593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd0eb31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:08.559086Z",
     "iopub.status.busy": "2021-08-05T18:18:08.558434Z",
     "iopub.status.idle": "2021-08-05T18:18:08.567015Z",
     "shell.execute_reply": "2021-08-05T18:18:08.567416Z",
     "shell.execute_reply.started": "2021-08-05T17:47:59.757646Z"
    },
    "papermill": {
     "duration": 0.029877,
     "end_time": "2021-08-05T18:18:08.567540",
     "exception": false,
     "start_time": "2021-08-05T18:18:08.537663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f87797cbcf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5960eaa2",
   "metadata": {
    "papermill": {
     "duration": 0.019501,
     "end_time": "2021-08-05T18:18:08.604717",
     "exception": false,
     "start_time": "2021-08-05T18:18:08.585216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17128432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:08.649218Z",
     "iopub.status.busy": "2021-08-05T18:18:08.648418Z",
     "iopub.status.idle": "2021-08-05T18:18:12.707857Z",
     "shell.execute_reply": "2021-08-05T18:18:12.708346Z",
     "shell.execute_reply.started": "2021-08-05T17:13:07.110660Z"
    },
    "papermill": {
     "duration": 4.083595,
     "end_time": "2021-08-05T18:18:12.708515",
     "exception": false,
     "start_time": "2021-08-05T18:18:08.624920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "unzip is already the newest version (6.0-21ubuntu1.1).\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\r\n",
      "Archive:  ../input/sentiment-analysis-on-movie-reviews/test.tsv.zip\r\n",
      "  inflating: test.tsv                \r\n",
      "Archive:  ../input/sentiment-analysis-on-movie-reviews/train.tsv.zip\r\n",
      "  inflating: train.tsv               \r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install unzip\n",
    "!unzip ../input/sentiment-analysis-on-movie-reviews/test.tsv.zip test.tsv\n",
    "!unzip ../input/sentiment-analysis-on-movie-reviews/train.tsv.zip train.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba2cfc8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:12.810461Z",
     "iopub.status.busy": "2021-08-05T18:18:12.809748Z",
     "iopub.status.idle": "2021-08-05T18:18:13.046714Z",
     "shell.execute_reply": "2021-08-05T18:18:13.047105Z",
     "shell.execute_reply.started": "2021-08-05T17:13:11.852172Z"
    },
    "papermill": {
     "duration": 0.312838,
     "end_time": "2021-08-05T18:18:13.047259",
     "exception": false,
     "start_time": "2021-08-05T18:18:12.734421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   PhraseId    156060 non-null  int64 \n",
      " 1   SentenceId  156060 non-null  int64 \n",
      " 2   Phrase      156060 non-null  object\n",
      " 3   Sentiment   156060 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sample_submission = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/sampleSubmission.csv')\n",
    "\n",
    "train = pd.read_csv('train.tsv', sep='\\t')\n",
    "print(train.shape)\n",
    "print(train.info())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a00bcc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:13.099126Z",
     "iopub.status.busy": "2021-08-05T18:18:13.098297Z",
     "iopub.status.idle": "2021-08-05T18:18:13.183375Z",
     "shell.execute_reply": "2021-08-05T18:18:13.183832Z",
     "shell.execute_reply.started": "2021-08-05T17:13:12.617570Z"
    },
    "papermill": {
     "duration": 0.113043,
     "end_time": "2021-08-05T18:18:13.183985",
     "exception": false,
     "start_time": "2021-08-05T18:18:13.070942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66292 entries, 0 to 66291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   PhraseId    66292 non-null  int64 \n",
      " 1   SentenceId  66292 non-null  int64 \n",
      " 2   Phrase      66292 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.tsv', sep='\\t')\n",
    "print(test.shape)\n",
    "print(test.info())\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4f0c8",
   "metadata": {
    "papermill": {
     "duration": 0.022726,
     "end_time": "2021-08-05T18:18:13.231781",
     "exception": false,
     "start_time": "2021-08-05T18:18:13.209055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe359b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:13.281385Z",
     "iopub.status.busy": "2021-08-05T18:18:13.280626Z",
     "iopub.status.idle": "2021-08-05T18:18:13.282850Z",
     "shell.execute_reply": "2021-08-05T18:18:13.283295Z",
     "shell.execute_reply.started": "2021-08-05T17:13:15.192974Z"
    },
    "papermill": {
     "duration": 0.028796,
     "end_time": "2021-08-05T18:18:13.283417",
     "exception": false,
     "start_time": "2021-08-05T18:18:13.254621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def clean_phrase(df):\n",
    "#     phrases = []\n",
    "#     for sent in tqdm(df['Phrase']):\n",
    "#         text = re.sub(\"[^a-zA-Z]\",\" \",sent)\n",
    "#         words = word_tokenize(text.lower())\n",
    "#         lemmatizer = WordNetLemmatizer()\n",
    "#         lem_word = [lemmatizer.lemmatize(word) for word in words]\n",
    "#         phrases.append(lem_word)\n",
    "\n",
    "#     return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437634cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:13.332808Z",
     "iopub.status.busy": "2021-08-05T18:18:13.332168Z",
     "iopub.status.idle": "2021-08-05T18:18:13.334533Z",
     "shell.execute_reply": "2021-08-05T18:18:13.334966Z",
     "shell.execute_reply.started": "2021-08-05T17:13:15.342363Z"
    },
    "papermill": {
     "duration": 0.029269,
     "end_time": "2021-08-05T18:18:13.335102",
     "exception": false,
     "start_time": "2021-08-05T18:18:13.305833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_phrase = clean_phrase(train)\n",
    "# test_phrase = clean_phrase(test)\n",
    "# print(\"Train:\", train_phrase[:10])\n",
    "# print(\"\\n Test:\", test_phrase[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e2ab85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:13.383958Z",
     "iopub.status.busy": "2021-08-05T18:18:13.383241Z",
     "iopub.status.idle": "2021-08-05T18:18:13.385989Z",
     "shell.execute_reply": "2021-08-05T18:18:13.385567Z",
     "shell.execute_reply.started": "2021-08-05T17:13:15.482410Z"
    },
    "papermill": {
     "duration": 0.028376,
     "end_time": "2021-08-05T18:18:13.386095",
     "exception": false,
     "start_time": "2021-08-05T18:18:13.357719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max_len = 0\n",
    "# for sample in train_phrase:\n",
    "#     if len(sample) > max_len:\n",
    "#         max_len = len(sample)\n",
    "\n",
    "# for sample in test_phrase:\n",
    "#     if len(sample) > max_len:\n",
    "#         max_len = len(sample)\n",
    "# max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd5cc72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:13.461931Z",
     "iopub.status.busy": "2021-08-05T18:18:13.456834Z",
     "iopub.status.idle": "2021-08-05T18:18:15.605357Z",
     "shell.execute_reply": "2021-08-05T18:18:15.605783Z",
     "shell.execute_reply.started": "2021-08-05T17:13:16.934700Z"
    },
    "papermill": {
     "duration": 2.197243,
     "end_time": "2021-08-05T18:18:15.605932",
     "exception": false,
     "start_time": "2021-08-05T18:18:13.408689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "full_corpus = train['Phrase'].tolist() + test['Phrase'].tolist()\n",
    "vectorizer.fit(full_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7132f44b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:15.661544Z",
     "iopub.status.busy": "2021-08-05T18:18:15.660816Z",
     "iopub.status.idle": "2021-08-05T18:18:15.663067Z",
     "shell.execute_reply": "2021-08-05T18:18:15.663483Z",
     "shell.execute_reply.started": "2021-08-05T17:13:30.505176Z"
    },
    "papermill": {
     "duration": 0.034705,
     "end_time": "2021-08-05T18:18:15.663613",
     "exception": false,
     "start_time": "2021-08-05T18:18:15.628908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MovieReviewsDataset(Dataset):\n",
    "    def __init__(self, vectorizer, df, max_len, test=False):\n",
    "        self.max_len = max_len\n",
    "        self.test = test\n",
    "        text = df['Phrase'].tolist()\n",
    "        if not self.test:\n",
    "            sentiments = df['Sentiment'].tolist()\n",
    "\n",
    "        self.token2idx = vectorizer.vocabulary_\n",
    "        self.token2idx['<PAD>'] = max(self.token2idx.values()) + 1\n",
    "\n",
    "        tokenizer = vectorizer.build_analyzer()\n",
    "\n",
    "        self.encode = lambda x: [self.token2idx[token] for token in tokenizer(x) if token in self.token2idx]\n",
    "        self.pad = lambda x: x + (self.max_len - len(x)) * [self.token2idx['<PAD>']]\n",
    "        \n",
    "        texts = [self.encode(sample) [:self.max_len] for sample in text]\n",
    "        if not self.test:\n",
    "            texts, self.labels = zip(*[(text, label) for text, label in zip(texts, sentiments) if text])\n",
    "        \n",
    "        self.texts = [self.pad(text) for text in texts]\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        if not self.test:\n",
    "            return self.texts[i], self.labels[i]\n",
    "        return self.texts[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa7bb91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:15.748056Z",
     "iopub.status.busy": "2021-08-05T18:18:15.737953Z",
     "iopub.status.idle": "2021-08-05T18:18:18.696021Z",
     "shell.execute_reply": "2021-08-05T18:18:18.696899Z",
     "shell.execute_reply.started": "2021-08-05T17:13:31.885476Z"
    },
    "papermill": {
     "duration": 3.010632,
     "end_time": "2021-08-05T18:18:18.697100",
     "exception": false,
     "start_time": "2021-08-05T18:18:15.686468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155907\n",
      "66292\n",
      "17730\n",
      "17730\n"
     ]
    }
   ],
   "source": [
    "max_len = 64\n",
    "train_dataset = MovieReviewsDataset(vectorizer, train, max_len)\n",
    "test_dataset = MovieReviewsDataset(vectorizer, test, max_len, test=True)\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(train_dataset.token2idx))\n",
    "print(len(test_dataset.token2idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d1c21",
   "metadata": {
    "papermill": {
     "duration": 0.022982,
     "end_time": "2021-08-05T18:18:18.744674",
     "exception": false,
     "start_time": "2021-08-05T18:18:18.721692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b62056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:18:18.795521Z",
     "iopub.status.busy": "2021-08-05T18:18:18.795019Z",
     "iopub.status.idle": "2021-08-05T18:19:07.663713Z",
     "shell.execute_reply": "2021-08-05T18:19:07.661750Z",
     "shell.execute_reply.started": "2021-08-05T17:13:36.392808Z"
    },
    "papermill": {
     "duration": 48.896157,
     "end_time": "2021-08-05T18:19:07.663903",
     "exception": false,
     "start_time": "2021-08-05T18:18:18.767746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started preparing glove embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:48, 8187.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "glove_embeddings = {}\n",
    "glove_file = open('../input/glove6b/glove.6B.300d.txt')\n",
    "print('Started preparing glove embeddings')\n",
    "for line in tqdm(glove_file):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    glove_embeddings[word] = coefs\n",
    "glove_file.close()\n",
    "print(f'Found {len(glove_embeddings)} word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56e0c814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:19:07.977487Z",
     "iopub.status.busy": "2021-08-05T18:19:07.976528Z",
     "iopub.status.idle": "2021-08-05T18:19:08.046499Z",
     "shell.execute_reply": "2021-08-05T18:19:08.045889Z",
     "shell.execute_reply.started": "2021-08-05T17:14:25.428436Z"
    },
    "papermill": {
     "duration": 0.227232,
     "end_time": "2021-08-05T18:19:08.046668",
     "exception": false,
     "start_time": "2021-08-05T18:19:07.819436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17731, 300)\n",
      "17730\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(train_dataset.token2idx) + 1, 300))\n",
    "for word, idx in train_dataset.token2idx.items():\n",
    "    if word in glove_embeddings.keys():\n",
    "        embedding_matrix[idx] = glove_embeddings[word]\n",
    "print(embedding_matrix.shape)\n",
    "print(len(train_dataset.token2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034749ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:19:08.362630Z",
     "iopub.status.busy": "2021-08-05T18:19:08.362022Z",
     "iopub.status.idle": "2021-08-05T18:19:08.389114Z",
     "shell.execute_reply": "2021-08-05T18:19:08.388679Z",
     "shell.execute_reply.started": "2021-08-05T17:14:25.512271Z"
    },
    "papermill": {
     "duration": 0.186098,
     "end_time": "2021-08-05T18:19:08.389241",
     "exception": false,
     "start_time": "2021-08-05T18:19:08.203143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lengths = [int(len(train_dataset) * 0.8), int(len(train_dataset) * 0.2 + 1)]\n",
    "train_dataset, valid_dataset = random_split(train_dataset, lengths=lengths, generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3102704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:19:08.705761Z",
     "iopub.status.busy": "2021-08-05T18:19:08.705053Z",
     "iopub.status.idle": "2021-08-05T18:19:08.707753Z",
     "shell.execute_reply": "2021-08-05T18:19:08.708125Z",
     "shell.execute_reply.started": "2021-08-05T18:10:41.236234Z"
    },
    "papermill": {
     "duration": 0.162983,
     "end_time": "2021-08-05T18:19:08.708269",
     "exception": false,
     "start_time": "2021-08-05T18:19:08.545286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    inputs = torch.LongTensor([item[0] for item in batch])\n",
    "    target = torch.LongTensor([item[1] for item in batch])\n",
    "    return inputs, target\n",
    "\n",
    "def test_collate(batch):\n",
    "    inputs = torch.LongTensor([item for item in batch])\n",
    "    return inputs\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, collate_fn=collate, shuffle=True)\n",
    "val_dataloader = DataLoader(valid_dataset, batch_size=128, collate_fn=collate)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, collate_fn=test_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee075022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:19:09.023843Z",
     "iopub.status.busy": "2021-08-05T18:19:09.023082Z",
     "iopub.status.idle": "2021-08-05T18:19:09.057502Z",
     "shell.execute_reply": "2021-08-05T18:19:09.056992Z",
     "shell.execute_reply.started": "2021-08-05T18:11:29.904041Z"
    },
    "papermill": {
     "duration": 0.193175,
     "end_time": "2021-08-05T18:19:09.057632",
     "exception": false,
     "start_time": "2021-08-05T18:19:08.864457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16963,  4842,  1230,  ..., 17729, 17729, 17729],\n",
      "        [15745,   705,   373,  ..., 17729, 17729, 17729],\n",
      "        [14653, 15714,   909,  ..., 17729, 17729, 17729],\n",
      "        ...,\n",
      "        [ 2534,   726, 14478,  ..., 17729, 17729, 17729],\n",
      "        [ 8408,     4,  9948,  ..., 17729, 17729, 17729],\n",
      "        [ 4285,  2489,  9749,  ..., 17729, 17729, 17729]])\n",
      "torch.Size([128, 64])\n",
      "975\n",
      "518\n"
     ]
    }
   ],
   "source": [
    "for text, s in train_dataloader:\n",
    "    print(text)\n",
    "    print(text.shape)\n",
    "    break\n",
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccf432ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:19:09.371873Z",
     "iopub.status.busy": "2021-08-05T18:19:09.371194Z",
     "iopub.status.idle": "2021-08-05T18:19:09.375249Z",
     "shell.execute_reply": "2021-08-05T18:19:09.375864Z",
     "shell.execute_reply.started": "2021-08-05T17:15:40.096478Z"
    },
    "papermill": {
     "duration": 0.164943,
     "end_time": "2021-08-05T18:19:09.376025",
     "exception": false,
     "start_time": "2021-08-05T18:19:09.211082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, embedding_matrix):\n",
    "        super(Model, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embeddings.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(2*hidden_size, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        out = self.embeddings(x)\n",
    "        out, _ = self.lstm(out)\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be05d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:19:09.684575Z",
     "iopub.status.busy": "2021-08-05T18:19:09.683621Z",
     "iopub.status.idle": "2021-08-05T18:19:14.340878Z",
     "shell.execute_reply": "2021-08-05T18:19:14.341709Z",
     "shell.execute_reply.started": "2021-08-05T17:51:26.074195Z"
    },
    "papermill": {
     "duration": 4.81482,
     "end_time": "2021-08-05T18:19:14.341886",
     "exception": false,
     "start_time": "2021-08-05T18:19:09.527066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    vocab_size=embedding_matrix.shape[0],\n",
    "    embedding_dim=embedding_matrix.shape[1],\n",
    "    hidden_size=128,\n",
    "    embedding_matrix=embedding_matrix,\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criteron = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd5033a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:19:14.662684Z",
     "iopub.status.busy": "2021-08-05T18:19:14.661935Z",
     "iopub.status.idle": "2021-08-05T18:22:30.784741Z",
     "shell.execute_reply": "2021-08-05T18:22:30.784225Z",
     "shell.execute_reply.started": "2021-08-05T17:51:26.239890Z"
    },
    "papermill": {
     "duration": 196.286016,
     "end_time": "2021-08-05T18:22:30.784865",
     "exception": false,
     "start_time": "2021-08-05T18:19:14.498849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:17<00:00, 54.31it/s]\n",
      "  0%|          | 0/244 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████| 244/244 [00:01<00:00, 148.17it/s]\n",
      "  1%|          | 6/975 [00:00<00:19, 50.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1 -- loss: 1.288803624373216 -- val acc: 0.512112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:17<00:00, 54.67it/s]\n",
      "100%|██████████| 244/244 [00:01<00:00, 149.87it/s]\n",
      "  1%|          | 5/975 [00:00<00:19, 49.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  2 -- loss: 1.285836686232151 -- val acc: 0.512112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:17<00:00, 54.36it/s]\n",
      "100%|██████████| 244/244 [00:01<00:00, 149.82it/s]\n",
      "  1%|          | 5/975 [00:00<00:19, 49.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  3 -- loss: 1.2853986379427789 -- val acc: 0.512112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:18<00:00, 54.10it/s]\n",
      "100%|██████████| 244/244 [00:01<00:00, 148.44it/s]\n",
      "  1%|          | 6/975 [00:00<00:19, 50.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  4 -- loss: 1.0601789264189891 -- val acc: 0.6275401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:17<00:00, 54.32it/s]\n",
      "100%|██████████| 244/244 [00:01<00:00, 148.63it/s]\n",
      "  1%|          | 6/975 [00:00<00:19, 50.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  5 -- loss: 0.8580988224958762 -- val acc: 0.64409363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:17<00:00, 54.18it/s]\n",
      "100%|██████████| 244/244 [00:01<00:00, 148.95it/s]\n",
      "  1%|          | 5/975 [00:00<00:19, 49.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  6 -- loss: 0.7948868875625806 -- val acc: 0.6644114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:18<00:00, 53.48it/s]\n",
      "100%|██████████| 244/244 [00:01<00:00, 146.87it/s]\n",
      "  1%|          | 6/975 [00:00<00:17, 54.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  7 -- loss: 0.7469737071257371 -- val acc: 0.663675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:17<00:00, 54.44it/s]\n",
      "100%|██████████| 244/244 [00:01<00:00, 150.70it/s]\n",
      "  1%|          | 5/975 [00:00<00:19, 49.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  8 -- loss: 0.7090354856466635 -- val acc: 0.67110574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:17<00:00, 54.43it/s]\n",
      "100%|██████████| 244/244 [00:01<00:00, 149.51it/s]\n",
      "  1%|          | 5/975 [00:00<00:19, 49.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  9 -- loss: 0.6806810829883967 -- val acc: 0.6681806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:17<00:00, 54.32it/s]\n",
      "100%|██████████| 244/244 [00:01<00:00, 151.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  10 -- loss: 0.65491398196954 -- val acc: 0.6710121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "total_loss = []\n",
    "total_val_acc = []\n",
    "for i in range(n_epochs):\n",
    "    loss_per_epoch = []\n",
    "    model.train()\n",
    "    for text, label in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        y_pred = model(text)\n",
    "        loss = criteron(y_pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_per_epoch.append(loss.item())\n",
    "    \n",
    "    val_accs = []\n",
    "    model.eval()\n",
    "    for text, label in tqdm(val_dataloader):\n",
    "        text, label = text.to(device), label.to(device)\n",
    "        y_pred = model(text)\n",
    "        _, y_pred = torch.max(y_pred, -1)\n",
    "        acc = torch.mean((torch.tensor(y_pred.cpu() == label.cpu(), dtype=torch.float)))\n",
    "        val_accs.append(acc.cpu())\n",
    "    \n",
    "    val_acc = np.array(val_accs).mean()\n",
    "    loss = sum(loss_per_epoch)/len(loss_per_epoch)\n",
    "    print(\"EPOCH: \", i+1, \"-- loss:\", loss, \"-- val acc:\", val_acc)\n",
    "    total_loss.append(loss)\n",
    "    total_val_acc.append(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfae01d",
   "metadata": {
    "papermill": {
     "duration": 0.6058,
     "end_time": "2021-08-05T18:22:31.993699",
     "exception": false,
     "start_time": "2021-08-05T18:22:31.387899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08149a24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:22:33.202430Z",
     "iopub.status.busy": "2021-08-05T18:22:33.201569Z",
     "iopub.status.idle": "2021-08-05T18:22:37.462771Z",
     "shell.execute_reply": "2021-08-05T18:22:37.460989Z",
     "shell.execute_reply.started": "2021-08-05T18:14:13.873454Z"
    },
    "papermill": {
     "duration": 4.865707,
     "end_time": "2021-08-05T18:22:37.462896",
     "exception": false,
     "start_time": "2021-08-05T18:22:32.597189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 518/518 [00:04<00:00, 121.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "for text in tqdm(test_dataloader):\n",
    "    text = text.to(device)\n",
    "    preds = model(text)\n",
    "    _, preds = torch.max(preds, -1)\n",
    "    for pred in preds: predictions.append(pred.item())\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74b49510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-05T18:22:38.693824Z",
     "iopub.status.busy": "2021-08-05T18:22:38.692990Z",
     "iopub.status.idle": "2021-08-05T18:22:38.833870Z",
     "shell.execute_reply": "2021-08-05T18:22:38.834411Z",
     "shell.execute_reply.started": "2021-08-05T18:17:20.844182Z"
    },
    "papermill": {
     "duration": 0.7587,
     "end_time": "2021-08-05T18:22:38.834610",
     "exception": false,
     "start_time": "2021-08-05T18:22:38.075910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sumbssion is ready!\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['PhraseId'] = test['PhraseId']\n",
    "submission['Sentiment'] = predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Sumbssion is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2bfda",
   "metadata": {
    "papermill": {
     "duration": 0.612745,
     "end_time": "2021-08-05T18:22:40.060774",
     "exception": false,
     "start_time": "2021-08-05T18:22:39.448029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 283.802178,
   "end_time": "2021-08-05T18:22:42.901060",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-05T18:17:59.098882",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

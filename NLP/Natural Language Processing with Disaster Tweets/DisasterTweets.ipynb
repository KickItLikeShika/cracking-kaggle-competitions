{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n",
      "(3263, 4)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "smaple = pd.read_csv('sample_submission.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "None\n",
      "=================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.info())\n",
    "print(\"=================\")\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['location', 'keyword'], axis=1, inplace=True)\n",
    "test.drop(['location', 'keyword'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 3), (3263, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "------------\n",
      "Forest fire near La Ronge Sask. Canada\n",
      "------------\n",
      "All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
      "------------\n",
      "13,000 people receive #wildfires evacuation orders in California \n",
      "------------\n",
      "Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n",
      "------------\n",
      "#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires\n",
      "------------\n",
      "#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas\n",
      "------------\n",
      "I'm on top of the hill and I can see a fire in the woods...\n",
      "------------\n",
      "There's an emergency evacuation happening now in the building across the street\n",
      "------------\n",
      "I'm afraid that the tornado is coming to our area...\n",
      "------------\n",
      "Three people died from the heat wave so far\n",
      "------------\n",
      "Haha South Tampa is getting flooded hah- WAIT A SECOND I LIVE IN SOUTH TAMPA WHAT AM I GONNA DO WHAT AM I GONNA DO FVCK #flooding\n",
      "------------\n",
      "#raining #flooding #Florida #TampaBay #Tampa 18 or 19 days. I've lost count \n",
      "------------\n",
      "#Flood in Bago Myanmar #We arrived Bago\n",
      "------------\n",
      "Damage to school bus on 80 in multi car crash #BREAKING \n",
      "------------\n",
      "What's up man?\n",
      "------------\n",
      "I love fruits\n",
      "------------\n",
      "Summer is lovely\n",
      "------------\n",
      "My car is so fast\n",
      "------------\n",
      "What a goooooooaaaaaal!!!!!!\n",
      "------------\n",
      "this is ridiculous....\n",
      "------------\n",
      "London is cool ;)\n",
      "------------\n",
      "Love skiing\n",
      "------------\n",
      "What a wonderful day!\n",
      "------------\n",
      "LOOOOOOL\n",
      "------------\n",
      "No way...I can't eat that shit\n",
      "------------\n",
      "Was in NYC last week!\n",
      "------------\n",
      "Love my girlfriend\n",
      "------------\n",
      "Cooool :)\n",
      "------------\n",
      "Do you like pasta?\n",
      "------------\n",
      "The end!\n",
      "------------\n",
      "@bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C\n",
      "------------\n",
      "We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw\n",
      "------------\n",
      "#AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi\n",
      "------------\n",
      "Crying out for more! Set me ablaze\n",
      "------------\n",
      "On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N\n",
      "------------\n",
      "@PhDSquares #mufc they've built so much hype around new acquisitions but I doubt they will set the EPL ablaze this season.\n",
      "------------\n",
      "INEC Office in Abia Set Ablaze - http://t.co/3ImaomknnA\n",
      "------------\n",
      "Barbados #Bridgetown JAMAICA ÛÒ Two cars set ablaze: SANTA CRUZ ÛÓ Head of the St Elizabeth Police Superintende...  http://t.co/wDUEaj8Q4J\n",
      "------------\n",
      "Ablaze for you Lord :D\n",
      "------------\n",
      "Check these out: http://t.co/rOI2NSmEJJ http://t.co/3Tj8ZjiN21 http://t.co/YDUiXEfIpE http://t.co/LxTjc87KLS #nsfw\n",
      "------------\n",
      "on the outside you're ablaze and alive\n",
      "but you're dead inside\n",
      "------------\n",
      "Had an awesome time visiting the CFC head office the ancop site and ablaze. Thanks to Tita Vida for taking care of us ??\n",
      "------------\n",
      "SOOOO PUMPED FOR ABLAZE ???? @southridgelife\n",
      "------------\n",
      "I wanted to set Chicago ablaze with my preaching... But not my hotel! http://t.co/o9qknbfOFX\n",
      "------------\n",
      "I gained 3 followers in the last week. You? Know your stats and grow with http://t.co/TIyUliF5c6\n",
      "------------\n",
      "How the West was burned: Thousands of wildfires ablaze in California alone http://t.co/vl5TBR3wbr\n",
      "------------\n",
      "Building the perfect tracklist to life leave the streets ablaze\n",
      "------------\n",
      "Check these out: http://t.co/rOI2NSmEJJ http://t.co/3Tj8ZjiN21 http://t.co/YDUiXEfIpE http://t.co/LxTjc87KLS #nsfw\n",
      "------------\n",
      "First night with retainers in. It's quite weird. Better get used to it; I have to wear them every single night for the next year at least.\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(train['text'][i])\n",
    "    print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', \n",
    "          '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', '·', '_', \n",
    "          '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×',\n",
    "          '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', \n",
    "          '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', \n",
    "          '‹', '─', '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', \n",
    "          'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', \n",
    "          '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', \n",
    "          'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5, }', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mispell_dict = {\"aren't\": \"are not\", \"can't\": \"cannot\", \n",
    "                \"couldn't\": \"could not\", \"didn't\": \"did not\",\n",
    "                \"doesn't\": \"does not\", \"don't\": \"do not\", \n",
    "                \"hadn't\": \"had not\", \"hasn't\": \"has not\",\n",
    "                \"haven't\": \"have not\", \"he'd\": \"he would\", \n",
    "                \"he'll\": \"he will\", \"he's\": \"he is\",\n",
    "                \"i'd\": \"I would\", \"i'd\": \"I had\", \"i'll\": \n",
    "                \"I will\", \"i'm\" : \"I am\", \"isn't\": \"is not\",\n",
    "                \"it's\": \"it is\", \"it'll\": \"it will\", \n",
    "                \"i've\" : \"I have\", \"let's\": \"let us\", \n",
    "                \"mightn't\": \"might not\", \"mustn't\": \"must not\", \n",
    "                \"shan't\" : \"shall not\", \"she'd\": \"she would\",\n",
    "                \"she'll\": \"she will\", \"she's\": \"she is\", \n",
    "                \"shouldn't\": \"should not\", \"that's\": \"that is\", \n",
    "                \"there's\": \"there is\",\"they'd\": \"they would\", \n",
    "                \"they'll\": \"they will\", \"they're\": \"they are\",\n",
    "                \"they've\": \"they have\", \"we'd\": \"we would\", \n",
    "                \"we're\": \"we are\", \"weren't\": \"were not\",\n",
    "                \"we've\": \"we have\", \"what'll\": \"what will\", \n",
    "                \"what're\": \"what are\", \"what's\": \"what is\", \n",
    "                \"what've\": \"what have\", \"where's\": \"where is\", \n",
    "                \"who'd\": \"who would\", \"who'll\": \"who will\",\n",
    "                \"who're\": \"who are\", \"who's\": \"who is\", \n",
    "                \"who've\": \"who have\", \"won't\": \"will not\",\n",
    "                \"wouldn't\" : \"would not\", \"you'd\": \"you would\", \n",
    "                \"you'll\": \"you will\", \"you're\": \"you are\",\n",
    "                \"you've\": \"you have\", \"'re\": \" are\", \n",
    "                \"wasn't\": \"was not\", \"we'll\": \" will\", \n",
    "                \"didn't\": \"did not\", \"tryin'\": \"trying\", \n",
    "                \"colour\": \"color\", \"centre\": \"center\",\n",
    "                \"didnt\": \"did not\", \"doesnt\": \"does not\",\n",
    "                \"isnt\": \"is not\", \"shouldnt\": \"should not\",\n",
    "                \"favourite\": \"favorite\", \"travelling\": \"traveling\",\n",
    "                \"counselling\": \"counseling\", \"theatre\": \"theater\",\n",
    "                \"cancelled\": \"canceled\", \"labour\": \"labor\",\n",
    "                \"organisation\": \"organization\", \"wwii\": \"world war 2\",\n",
    "                \"citicise\": \"criticize\", \"instagram\": \"social medium\",\n",
    "                \"whatsapp\": \"social medium\", \"snapchat\": \"social medium\"}\n",
    "\n",
    "\n",
    "def get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({\"aren't\": 'are not',\n",
       "  \"can't\": 'cannot',\n",
       "  \"couldn't\": 'could not',\n",
       "  \"didn't\": 'did not',\n",
       "  \"doesn't\": 'does not',\n",
       "  \"don't\": 'do not',\n",
       "  \"hadn't\": 'had not',\n",
       "  \"hasn't\": 'has not',\n",
       "  \"haven't\": 'have not',\n",
       "  \"he'd\": 'he would',\n",
       "  \"he'll\": 'he will',\n",
       "  \"he's\": 'he is',\n",
       "  \"i'd\": 'I had',\n",
       "  \"i'll\": 'I will',\n",
       "  \"i'm\": 'I am',\n",
       "  \"isn't\": 'is not',\n",
       "  \"it's\": 'it is',\n",
       "  \"it'll\": 'it will',\n",
       "  \"i've\": 'I have',\n",
       "  \"let's\": 'let us',\n",
       "  \"mightn't\": 'might not',\n",
       "  \"mustn't\": 'must not',\n",
       "  \"shan't\": 'shall not',\n",
       "  \"she'd\": 'she would',\n",
       "  \"she'll\": 'she will',\n",
       "  \"she's\": 'she is',\n",
       "  \"shouldn't\": 'should not',\n",
       "  \"that's\": 'that is',\n",
       "  \"there's\": 'there is',\n",
       "  \"they'd\": 'they would',\n",
       "  \"they'll\": 'they will',\n",
       "  \"they're\": 'they are',\n",
       "  \"they've\": 'they have',\n",
       "  \"we'd\": 'we would',\n",
       "  \"we're\": 'we are',\n",
       "  \"weren't\": 'were not',\n",
       "  \"we've\": 'we have',\n",
       "  \"what'll\": 'what will',\n",
       "  \"what're\": 'what are',\n",
       "  \"what's\": 'what is',\n",
       "  \"what've\": 'what have',\n",
       "  \"where's\": 'where is',\n",
       "  \"who'd\": 'who would',\n",
       "  \"who'll\": 'who will',\n",
       "  \"who're\": 'who are',\n",
       "  \"who's\": 'who is',\n",
       "  \"who've\": 'who have',\n",
       "  \"won't\": 'will not',\n",
       "  \"wouldn't\": 'would not',\n",
       "  \"you'd\": 'you would',\n",
       "  \"you'll\": 'you will',\n",
       "  \"you're\": 'you are',\n",
       "  \"you've\": 'you have',\n",
       "  \"'re\": ' are',\n",
       "  \"wasn't\": 'was not',\n",
       "  \"we'll\": ' will',\n",
       "  \"tryin'\": 'trying',\n",
       "  'colour': 'color',\n",
       "  'centre': 'center',\n",
       "  'didnt': 'did not',\n",
       "  'doesnt': 'does not',\n",
       "  'isnt': 'is not',\n",
       "  'shouldnt': 'should not',\n",
       "  'favourite': 'favorite',\n",
       "  'travelling': 'traveling',\n",
       "  'counselling': 'counseling',\n",
       "  'theatre': 'theater',\n",
       "  'cancelled': 'canceled',\n",
       "  'labour': 'labor',\n",
       "  'organisation': 'organization',\n",
       "  'wwii': 'world war 2',\n",
       "  'citicise': 'criticize',\n",
       "  'instagram': 'social medium',\n",
       "  'whatsapp': 'social medium',\n",
       "  'snapchat': 'social medium'},\n",
       " re.compile(r\"(aren't|can't|couldn't|didn't|doesn't|don't|hadn't|hasn't|haven't|he'd|he'll|he's|i'd|i'll|i'm|isn't|it's|it'll|i've|let's|mightn't|mustn't|shan't|she'd|she'll|she's|shouldn't|that's|there's|they'd|they'll|they're|they've|we'd|we're|weren't|we've|what'll|what're|what's|what've|where's|who'd|who'll|who're|who's|who've|won't|wouldn't|you'd|you'll|you're|you've|'re|wasn't|we'll|tryin'|colour|centre|didnt|doesnt|isnt|shouldnt|favourite|travelling|counselling|theatre|cancelled|labour|organisation|wwii|citicise|instagram|whatsapp|snapchat)\",\n",
       " re.UNICODE))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mispellings, mispellings_re = get_mispell(mispell_dict)\n",
    "mispellings, mispellings_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(sentence):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    return emoji_pattern.sub(r'', sentence)\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    words = sentence.split()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def stem_words(sentence):\n",
    "    words = sentence.split()\n",
    "    words = [stemmer.stem(word) for word in words ]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: clean_text(x.lower()))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: clean_text(x.lower()))\n",
    "\n",
    "# Clean numbers\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: clean_numbers(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: clean_numbers(x))\n",
    "\n",
    "# Clean spellings\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: replace_typical_misspell(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: replace_typical_misspell(x))\n",
    "\n",
    "# Clear emojis\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: remove_emoji(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: remove_emoji(x))\n",
    "\n",
    "# Stopwords\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: remove_stopwords(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# Stemming\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: stem_words(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: stem_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deed reason # earthquak may allah forgiv us\n",
      "------------\n",
      "forest fire near la rong sask . canada\n",
      "------------\n",
      "resid ask ' shelter place ' notifi offic . evacu shelter place order expect\n",
      "------------\n",
      "## , ### peopl receiv # wildfir evacu order california\n",
      "------------\n",
      "got sent photo rubi # alaska smoke # wildfir pour school\n",
      "------------\n",
      "# rockyfir updat = > california hwi . ## close direct due lake counti fire - # cafir # wildfir\n",
      "------------\n",
      "# flood # disast heavi rain caus flash flood street manitou , colorado spring area\n",
      "------------\n",
      "' top hill see fire wood . . .\n",
      "------------\n",
      "' emerg evacu happen build across street\n",
      "------------\n",
      "' afraid tornado come area . . .\n",
      "------------\n",
      "three peopl die heat wave far\n",
      "------------\n",
      "haha south tampa get flood hah - wait second live south tampa gonna gonna fvck # flood\n",
      "------------\n",
      "# rain # flood # florida # tampabay # tampa ## ## day . ' lost count\n",
      "------------\n",
      "# flood bago myanmar # arriv bago\n",
      "------------\n",
      "damag school bus ## multi car crash # break\n",
      "------------\n",
      "' man ?\n",
      "------------\n",
      "love fruit\n",
      "------------\n",
      "summer love\n",
      "------------\n",
      "car fast\n",
      "------------\n",
      "goooooooaaaaaal ! ! ! ! ! !\n",
      "------------\n",
      "ridicul . . . .\n",
      "------------\n",
      "london cool ; )\n",
      "------------\n",
      "love ski\n",
      "------------\n",
      "wonder day !\n",
      "------------\n",
      "looooool\n",
      "------------\n",
      "way . . . ' eat shit\n",
      "------------\n",
      "nyc last week !\n",
      "------------\n",
      "love girlfriend\n",
      "------------\n",
      "cooool : )\n",
      "------------\n",
      "like pasta ?\n",
      "------------\n",
      "end !\n",
      "------------\n",
      "@ bbcmtd wholesal market ablaz http : / / . co / lhyxeohy6c\n",
      "------------\n",
      "alway tri bring heavi . # metal # rt http : / / . co / yao1e0xngw\n",
      "------------\n",
      "# africanbaz : break news : nigeria flag set ablaz aba . http : / / . co / 2nndbgwyei\n",
      "------------\n",
      "cri ! set ablaz\n",
      "------------\n",
      "plus side look sky last night ablaz http : / / . co / qqsmshaj3n\n",
      "------------\n",
      "@ phdsquar # mufc ' built much hype around new acquisit doubt set epl ablaz season .\n",
      "------------\n",
      "inec offic abia set ablaz - http : / / . co / 3imaomknna\n",
      "------------\n",
      "barbado # bridgetown jamaica ûò two car set ablaz : santa cruz ûó head st elizabeth polic superintend . . . http : / / . co / wdueaj8q4j\n",
      "------------\n",
      "ablaz lord :\n",
      "------------\n",
      "check : http : / / . co / roi2nsmejj http : / / . co / 3tj8zjin## http : / / . co / yduixefip http : / / . co / lxtjc##kls # nsfw\n",
      "------------\n",
      "outsid ' ablaz aliv ' dead insid\n",
      "------------\n",
      "awesom time visit cfc head offic ancop site ablaz . thank tita vida take care us ? ?\n",
      "------------\n",
      "soooo pump ablaz ? ? ? ? @ southridgelif\n",
      "------------\n",
      "want set chicago ablaz preach . . . hotel ! http : / / . co / o9qknbfofx\n",
      "------------\n",
      "gain 3 follow last week . ? know stat grow http : / / . co / tiyulif5c6\n",
      "------------\n",
      "west burn : thousand wildfir ablaz california alon http : / / . co / vl5tbr3wbr\n",
      "------------\n",
      "build perfect tracklist life leav street ablaz\n",
      "------------\n",
      "check : http : / / . co / roi2nsmejj http : / / . co / 3tj8zjin## http : / / . co / yduixefip http : / / . co / lxtjc##kls # nsfw\n",
      "------------\n",
      "first night retain . ' quit weird . better get use ; wear everi singl night next year least .\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(train['text'][i])\n",
    "    print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = train.tail(1500)\n",
    "train_data = train.head(6113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

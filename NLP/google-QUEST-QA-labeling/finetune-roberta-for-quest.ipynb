{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2debaf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:28:43.288254Z",
     "iopub.status.busy": "2021-08-22T14:28:43.287601Z",
     "iopub.status.idle": "2021-08-22T14:28:50.297940Z",
     "shell.execute_reply": "2021-08-22T14:28:50.297360Z",
     "shell.execute_reply.started": "2021-08-22T11:04:47.571393Z"
    },
    "papermill": {
     "duration": 7.032389,
     "end_time": "2021-08-22T14:28:50.298082",
     "exception": false,
     "start_time": "2021-08-22T14:28:43.265693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import gc\n",
    "from math import floor, ceil\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "\n",
    "pd.set_option('max_column', 50)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c99f288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:28:50.321264Z",
     "iopub.status.busy": "2021-08-22T14:28:50.320631Z",
     "iopub.status.idle": "2021-08-22T14:28:50.327133Z",
     "shell.execute_reply": "2021-08-22T14:28:50.326646Z",
     "shell.execute_reply.started": "2021-08-22T11:04:55.987512Z"
    },
    "papermill": {
     "duration": 0.019633,
     "end_time": "2021-08-22T14:28:50.327239",
     "exception": false,
     "start_time": "2021-08-22T14:28:50.307606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e81788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:28:50.395292Z",
     "iopub.status.busy": "2021-08-22T14:28:50.394702Z",
     "iopub.status.idle": "2021-08-22T14:28:50.774326Z",
     "shell.execute_reply": "2021-08-22T14:28:50.774799Z",
     "shell.execute_reply.started": "2021-08-22T11:04:58.675782Z"
    },
    "papermill": {
     "duration": 0.439056,
     "end_time": "2021-08-22T14:28:50.774969",
     "exception": false,
     "start_time": "2021-08-22T14:28:50.335913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6079 entries, 0 to 6078\n",
      "Data columns (total 41 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   qa_id                                  6079 non-null   int64  \n",
      " 1   question_title                         6079 non-null   object \n",
      " 2   question_body                          6079 non-null   object \n",
      " 3   question_user_name                     6079 non-null   object \n",
      " 4   question_user_page                     6079 non-null   object \n",
      " 5   answer                                 6079 non-null   object \n",
      " 6   answer_user_name                       6079 non-null   object \n",
      " 7   answer_user_page                       6079 non-null   object \n",
      " 8   url                                    6079 non-null   object \n",
      " 9   category                               6079 non-null   object \n",
      " 10  host                                   6079 non-null   object \n",
      " 11  question_asker_intent_understanding    6079 non-null   float64\n",
      " 12  question_body_critical                 6079 non-null   float64\n",
      " 13  question_conversational                6079 non-null   float64\n",
      " 14  question_expect_short_answer           6079 non-null   float64\n",
      " 15  question_fact_seeking                  6079 non-null   float64\n",
      " 16  question_has_commonly_accepted_answer  6079 non-null   float64\n",
      " 17  question_interestingness_others        6079 non-null   float64\n",
      " 18  question_interestingness_self          6079 non-null   float64\n",
      " 19  question_multi_intent                  6079 non-null   float64\n",
      " 20  question_not_really_a_question         6079 non-null   float64\n",
      " 21  question_opinion_seeking               6079 non-null   float64\n",
      " 22  question_type_choice                   6079 non-null   float64\n",
      " 23  question_type_compare                  6079 non-null   float64\n",
      " 24  question_type_consequence              6079 non-null   float64\n",
      " 25  question_type_definition               6079 non-null   float64\n",
      " 26  question_type_entity                   6079 non-null   float64\n",
      " 27  question_type_instructions             6079 non-null   float64\n",
      " 28  question_type_procedure                6079 non-null   float64\n",
      " 29  question_type_reason_explanation       6079 non-null   float64\n",
      " 30  question_type_spelling                 6079 non-null   float64\n",
      " 31  question_well_written                  6079 non-null   float64\n",
      " 32  answer_helpful                         6079 non-null   float64\n",
      " 33  answer_level_of_information            6079 non-null   float64\n",
      " 34  answer_plausible                       6079 non-null   float64\n",
      " 35  answer_relevance                       6079 non-null   float64\n",
      " 36  answer_satisfaction                    6079 non-null   float64\n",
      " 37  answer_type_instructions               6079 non-null   float64\n",
      " 38  answer_type_procedure                  6079 non-null   float64\n",
      " 39  answer_type_reason_explanation         6079 non-null   float64\n",
      " 40  answer_well_written                    6079 non-null   float64\n",
      "dtypes: float64(30), int64(1), object(10)\n",
      "memory usage: 1.9+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>photo.stackexchange.com</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>rpg.stackexchange.com</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>electronics.stackexchange.com</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>judaism.stackexchange.com</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>graphicdesign.stackexchange.com</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0      0  What am I losing when using extension tubes in...   \n",
       "1      1  What is the distinction between a city and a s...   \n",
       "2      2  Maximum protusion length for through-hole comp...   \n",
       "3      3              Can an affidavit be used in Beit Din?   \n",
       "4      5       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  After playing around with macro photography on...               ysap   \n",
       "1  I am trying to understand what kinds of places...      russellpierce   \n",
       "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4  I am trying to make a binary image. I want mor...            leigero   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1024   \n",
       "1           https://rpg.stackexchange.com/users/8774   \n",
       "2  https://electronics.stackexchange.com/users/10157   \n",
       "3       https://judaism.stackexchange.com/users/5151   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  I just got extension tubes, so here's the skin...           rfusca   \n",
       "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
       "\n",
       "                                    answer_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1917   \n",
       "1           https://rpg.stackexchange.com/users/1871   \n",
       "2  https://electronics.stackexchange.com/users/64754   \n",
       "3       https://judaism.stackexchange.com/users/4794   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                                 url   category  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE   \n",
       "2  http://electronics.stackexchange.com/questions...    SCIENCE   \n",
       "3  http://judaism.stackexchange.com/questions/551...    CULTURE   \n",
       "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS   \n",
       "\n",
       "                              host  question_asker_intent_understanding  \\\n",
       "0          photo.stackexchange.com                             1.000000   \n",
       "1            rpg.stackexchange.com                             1.000000   \n",
       "2    electronics.stackexchange.com                             0.888889   \n",
       "3        judaism.stackexchange.com                             0.888889   \n",
       "4  graphicdesign.stackexchange.com                             1.000000   \n",
       "\n",
       "   question_body_critical  question_conversational  \\\n",
       "0                0.333333                 0.000000   \n",
       "1                1.000000                 0.000000   \n",
       "2                0.666667                 0.000000   \n",
       "3                0.666667                 0.666667   \n",
       "4                0.666667                 0.000000   \n",
       "\n",
       "   question_expect_short_answer  question_fact_seeking  \\\n",
       "0                           0.0                    0.0   \n",
       "1                           0.5                    1.0   \n",
       "2                           1.0                    1.0   \n",
       "3                           1.0                    1.0   \n",
       "4                           1.0                    1.0   \n",
       "\n",
       "   question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "0                                    0.0                         1.000000   \n",
       "1                                    1.0                         0.444444   \n",
       "2                                    1.0                         0.666667   \n",
       "3                                    1.0                         0.444444   \n",
       "4                                    1.0                         0.666667   \n",
       "\n",
       "   question_interestingness_self  question_multi_intent  \\\n",
       "0                       1.000000               0.000000   \n",
       "1                       0.444444               0.666667   \n",
       "2                       0.444444               0.333333   \n",
       "3                       0.444444               0.000000   \n",
       "4                       0.666667               0.000000   \n",
       "\n",
       "   question_not_really_a_question  question_opinion_seeking  \\\n",
       "0                             0.0                  1.000000   \n",
       "1                             0.0                  0.000000   \n",
       "2                             0.0                  0.333333   \n",
       "3                             0.0                  0.000000   \n",
       "4                             0.0                  0.000000   \n",
       "\n",
       "   question_type_choice  question_type_compare  question_type_consequence  \\\n",
       "0              0.000000               0.000000                        0.0   \n",
       "1              0.666667               0.666667                        0.0   \n",
       "2              0.000000               0.000000                        0.0   \n",
       "3              1.000000               0.000000                        0.0   \n",
       "4              0.000000               0.000000                        0.0   \n",
       "\n",
       "   question_type_definition  question_type_entity  question_type_instructions  \\\n",
       "0                  0.000000                   0.0                         1.0   \n",
       "1                  0.333333                   0.0                         0.0   \n",
       "2                  0.000000                   0.0                         1.0   \n",
       "3                  0.000000                   0.0                         0.0   \n",
       "4                  0.000000                   0.0                         1.0   \n",
       "\n",
       "   question_type_procedure  question_type_reason_explanation  \\\n",
       "0                 0.000000                          0.000000   \n",
       "1                 0.000000                          0.333333   \n",
       "2                 0.333333                          0.333333   \n",
       "3                 0.000000                          0.000000   \n",
       "4                 0.000000                          1.000000   \n",
       "\n",
       "   question_type_spelling  question_well_written  answer_helpful  \\\n",
       "0                     0.0               1.000000        1.000000   \n",
       "1                     0.0               0.888889        0.888889   \n",
       "2                     0.0               0.777778        0.777778   \n",
       "3                     0.0               0.888889        0.833333   \n",
       "4                     0.0               1.000000        1.000000   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.666667          1.000000          1.000000   \n",
       "1                     0.555556          0.888889          0.888889   \n",
       "2                     0.555556          1.000000          1.000000   \n",
       "3                     0.333333          0.833333          1.000000   \n",
       "4                     0.666667          1.000000          1.000000   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.800000                       1.0               0.000000   \n",
       "1             0.666667                       0.0               0.000000   \n",
       "2             0.666667                       0.0               0.333333   \n",
       "3             0.800000                       0.0               0.000000   \n",
       "4             0.800000                       1.0               0.000000   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.000000             1.000000  \n",
       "1                        0.666667             0.888889  \n",
       "2                        1.000000             0.888889  \n",
       "3                        1.000000             1.000000  \n",
       "4                        1.000000             1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_df = pd.read_csv('../input/google-quest-challenge/train.csv')\n",
    "\n",
    "print(train_df.info())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d79080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:28:50.799883Z",
     "iopub.status.busy": "2021-08-22T14:28:50.799223Z",
     "iopub.status.idle": "2021-08-22T14:28:50.855235Z",
     "shell.execute_reply": "2021-08-22T14:28:50.855662Z",
     "shell.execute_reply.started": "2021-08-22T11:04:59.236786Z"
    },
    "papermill": {
     "duration": 0.070784,
     "end_time": "2021-08-22T14:28:50.855809",
     "exception": false,
     "start_time": "2021-08-22T14:28:50.785025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476 entries, 0 to 475\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   qa_id               476 non-null    int64 \n",
      " 1   question_title      476 non-null    object\n",
      " 2   question_body       476 non-null    object\n",
      " 3   question_user_name  476 non-null    object\n",
      " 4   question_user_page  476 non-null    object\n",
      " 5   answer              476 non-null    object\n",
      " 6   answer_user_name    476 non-null    object\n",
      " 7   answer_user_page    476 non-null    object\n",
      " 8   url                 476 non-null    object\n",
      " 9   category            476 non-null    object\n",
      " 10  host                476 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 41.0+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/google-quest-challenge/test.csv')\n",
    "\n",
    "print(test_df.info())\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b2ccdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:28:50.882569Z",
     "iopub.status.busy": "2021-08-22T14:28:50.882068Z",
     "iopub.status.idle": "2021-08-22T14:28:50.924926Z",
     "shell.execute_reply": "2021-08-22T14:28:50.924448Z",
     "shell.execute_reply.started": "2021-08-22T11:04:59.319795Z"
    },
    "papermill": {
     "duration": 0.057309,
     "end_time": "2021-08-22T14:28:50.925051",
     "exception": false,
     "start_time": "2021-08-22T14:28:50.867742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                              0.00308                 0.00308   \n",
       "1     46                              0.00448                 0.00448   \n",
       "2     70                              0.00673                 0.00673   \n",
       "3    132                              0.01401                 0.01401   \n",
       "4    200                              0.02074                 0.02074   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                  0.00308                       0.00308   \n",
       "1                  0.00448                       0.00448   \n",
       "2                  0.00673                       0.00673   \n",
       "3                  0.01401                       0.01401   \n",
       "4                  0.02074                       0.02074   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.00308                                0.00308   \n",
       "1                0.00448                                0.00448   \n",
       "2                0.00673                                0.00673   \n",
       "3                0.01401                                0.01401   \n",
       "4                0.02074                                0.02074   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.00308                        0.00308   \n",
       "1                          0.00448                        0.00448   \n",
       "2                          0.00673                        0.00673   \n",
       "3                          0.01401                        0.01401   \n",
       "4                          0.02074                        0.02074   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  \\\n",
       "0                0.00308                         0.00308   \n",
       "1                0.00448                         0.00448   \n",
       "2                0.00673                         0.00673   \n",
       "3                0.01401                         0.01401   \n",
       "4                0.02074                         0.02074   \n",
       "\n",
       "   question_opinion_seeking  question_type_choice  question_type_compare  \\\n",
       "0                   0.00308               0.00308                0.00308   \n",
       "1                   0.00448               0.00448                0.00448   \n",
       "2                   0.00673               0.00673                0.00673   \n",
       "3                   0.01401               0.01401                0.01401   \n",
       "4                   0.02074               0.02074                0.02074   \n",
       "\n",
       "   question_type_consequence  question_type_definition  question_type_entity  \\\n",
       "0                    0.00308                   0.00308               0.00308   \n",
       "1                    0.00448                   0.00448               0.00448   \n",
       "2                    0.00673                   0.00673               0.00673   \n",
       "3                    0.01401                   0.01401               0.01401   \n",
       "4                    0.02074                   0.02074               0.02074   \n",
       "\n",
       "   question_type_instructions  question_type_procedure  \\\n",
       "0                     0.00308                  0.00308   \n",
       "1                     0.00448                  0.00448   \n",
       "2                     0.00673                  0.00673   \n",
       "3                     0.01401                  0.01401   \n",
       "4                     0.02074                  0.02074   \n",
       "\n",
       "   question_type_reason_explanation  question_type_spelling  \\\n",
       "0                           0.00308                 0.00308   \n",
       "1                           0.00448                 0.00448   \n",
       "2                           0.00673                 0.00673   \n",
       "3                           0.01401                 0.01401   \n",
       "4                           0.02074                 0.02074   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0                0.00308         0.00308                      0.00308   \n",
       "1                0.00448         0.00448                      0.00448   \n",
       "2                0.00673         0.00673                      0.00673   \n",
       "3                0.01401         0.01401                      0.01401   \n",
       "4                0.02074         0.02074                      0.02074   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0           0.00308           0.00308              0.00308   \n",
       "1           0.00448           0.00448              0.00448   \n",
       "2           0.00673           0.00673              0.00673   \n",
       "3           0.01401           0.01401              0.01401   \n",
       "4           0.02074           0.02074              0.02074   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                   0.00308                0.00308   \n",
       "1                   0.00448                0.00448   \n",
       "2                   0.00673                0.00673   \n",
       "3                   0.01401                0.01401   \n",
       "4                   0.02074                0.02074   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                         0.00308              0.00308  \n",
       "1                         0.00448              0.00448  \n",
       "2                         0.00673              0.00673  \n",
       "3                         0.01401              0.01401  \n",
       "4                         0.02074              0.02074  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('../input/google-quest-challenge/sample_submission.csv')\n",
    "TARGET_COLUMNS = sub.columns.values[1:].tolist()\n",
    "TARGET_COLUMNS\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b82325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:28:50.976811Z",
     "iopub.status.busy": "2021-08-22T14:28:50.974929Z",
     "iopub.status.idle": "2021-08-22T14:28:50.977411Z",
     "shell.execute_reply": "2021-08-22T14:28:50.977831Z",
     "shell.execute_reply.started": "2021-08-22T11:04:59.379264Z"
    },
    "papermill": {
     "duration": 0.040723,
     "end_time": "2021-08-22T14:28:50.977978",
     "exception": false,
     "start_time": "2021-08-22T14:28:50.937255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "SEP_TOKEN = 102\n",
    "\n",
    "class QUESTDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, train_mode=True, labeled=True):\n",
    "        self.df = df\n",
    "        self.train_mode = train_mode\n",
    "        self.labeled = labeled\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        input_ids, seg_ids, attention_mask = self.get_token_ids(row)\n",
    "#         attention_mask = (input_ids > 0)\n",
    "        if self.labeled:\n",
    "            labels = self.get_label(row)\n",
    "            return input_ids, seg_ids, attention_mask, labels\n",
    "        else:\n",
    "            return input_ids, seg_ids, attention_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def select_tokens(self, tokens, max_num):\n",
    "        if len(tokens) <= max_num:\n",
    "            return tokens\n",
    "        if self.train_mode:\n",
    "            num_remove = len(tokens) - max_num\n",
    "            remove_start = random.randint(0, len(tokens)-num_remove-1)\n",
    "            return tokens[:remove_start] + tokens[remove_start + num_remove:]\n",
    "        else:\n",
    "            return tokens[:max_num//2] + tokens[-(max_num - max_num//2):]\n",
    "            \n",
    "    def trim_input(self, title, question, answer, max_sequence_length=MAX_LEN, \n",
    "                t_max_len=30, q_max_len=238, a_max_len=238):\n",
    "        t = self.tokenizer.tokenize(title)\n",
    "        q = self.tokenizer.tokenize(question)\n",
    "        a = self.tokenizer.tokenize(answer)\n",
    "        t_len = len(t)\n",
    "        q_len = len(q)\n",
    "        a_len = len(a)\n",
    "        \n",
    "        if (t_len+q_len+a_len+6) > max_sequence_length:\n",
    "            if t_max_len > t_len:\n",
    "                t_new_len = t_len\n",
    "                a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "                q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "            else:\n",
    "                t_new_len = t_max_len\n",
    "\n",
    "            if a_max_len > a_len:\n",
    "                a_new_len = a_len \n",
    "                q_new_len = q_max_len + (a_max_len - a_len)\n",
    "            elif q_max_len > q_len:\n",
    "                a_new_len = a_max_len + (q_max_len - q_len)\n",
    "                q_new_len = q_len\n",
    "            else:\n",
    "                a_new_len = a_max_len\n",
    "                q_new_len = q_max_len\n",
    "\n",
    "\n",
    "            if t_new_len+a_new_len+q_new_len+6 != max_sequence_length:\n",
    "                raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                                 % (max_sequence_length, (t_new_len+a_new_len+q_new_len+6)))\n",
    "\n",
    "            if t_len > t_new_len:\n",
    "                ind1 = floor(t_new_len/2)\n",
    "                ind2 = ceil(t_new_len/2)\n",
    "                t = t[:ind1]+t[-ind2:]\n",
    "            else:\n",
    "                t = t[:t_new_len]\n",
    "\n",
    "            if q_len > q_new_len:\n",
    "                ind1 = floor(q_new_len/2)\n",
    "                ind2 = ceil(q_new_len/2)\n",
    "                q = q[:ind1]+q[-ind2:]\n",
    "            else:\n",
    "                q = q[:q_new_len]\n",
    "\n",
    "            if a_len > a_new_len:\n",
    "                ind1 = floor(a_new_len/2)\n",
    "                ind2 = ceil(a_new_len/2)\n",
    "                a = a[:ind1]+a[-ind2:]\n",
    "            else:\n",
    "                a = a[:a_new_len]\n",
    "\n",
    "        return t, q, a\n",
    "\n",
    "    def get_attention_masks(self, tokens):\n",
    "        if len(tokens) > 512:\n",
    "            raise IndexError(\"Token length more than max seq length!\")\n",
    "        return [1]*len(tokens) + [0] * (512 - len(tokens))\n",
    "\n",
    "    def get_seg_ids(self, ids):\n",
    "        seq_ids = torch.zeros_like(ids)\n",
    "        seq_idx = 0\n",
    "        first_sep = True\n",
    "        sep_token = self.tokenizer.sep_token\n",
    "        for i, e in enumerate(ids):\n",
    "            seq_ids[i] = seq_idx\n",
    "            if e == sep_token:\n",
    "                if first_sep:\n",
    "                    first_sep = False\n",
    "                else:\n",
    "                    seq_idx = 1\n",
    "        pad_idx = torch.nonzero(ids == 0)\n",
    "        seq_ids[pad_idx] = 0\n",
    "\n",
    "        return seq_ids\n",
    "    \n",
    "    def get_token_ids(self, row):\n",
    "        t_tokens, q_tokens, a_tokens = self.trim_input(row.question_title, row.question_body, row.answer)\n",
    "        tokens = ['<s>'] + t_tokens + ['</s>','</s>'] + q_tokens + ['</s>','</s>'] + a_tokens + ['</s>']\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        if len(token_ids) < MAX_LEN:\n",
    "            token_ids += [self.tokenizer.pad_token_id] * (MAX_LEN - len(token_ids)) # padding\n",
    "        \n",
    "        ids = torch.tensor(token_ids)\n",
    "        seg = self.get_seg_ids(ids)\n",
    "        attention_masks = self.get_attention_masks(tokens)\n",
    "        attention_masks = torch.tensor(attention_masks)\n",
    "        return ids, seg, attention_masks\n",
    "\n",
    "    def get_label(self, row):\n",
    "        return torch.tensor(row[TARGET_COLUMNS].values.astype(np.float32))\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        input_ids = torch.stack([x[0] for x in batch])\n",
    "        seg_ids = torch.stack([x[1] for x in batch])\n",
    "        attention_mask = torch.stack([x[2] for x in batch])\n",
    "        \n",
    "        if self.labeled:\n",
    "            labels = torch.stack([x[3] for x in batch])\n",
    "            return input_ids, seg_ids, attention_mask, labels\n",
    "        else:\n",
    "            return input_ids, seg_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "516f5018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:28:51.008431Z",
     "iopub.status.busy": "2021-08-22T14:28:51.007887Z",
     "iopub.status.idle": "2021-08-22T14:28:51.011988Z",
     "shell.execute_reply": "2021-08-22T14:28:51.011571Z",
     "shell.execute_reply.started": "2021-08-22T11:04:59.417351Z"
    },
    "papermill": {
     "duration": 0.022242,
     "end_time": "2021-08-22T14:28:51.012109",
     "exception": false,
     "start_time": "2021-08-22T14:28:50.989867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_loader(tokenizer, batch_size=4):\n",
    "    test_dataset = QUESTDataset(test_df, tokenizer, train_mode=False, labeled=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=test_dataset.collate_fn, drop_last=False)\n",
    "    test_loader.num = len(test_df)\n",
    "    \n",
    "    return test_loader\n",
    "\n",
    "\n",
    "def get_train_val_loaders(df, tokenizer, batch_size=4, val_batch_size=4, ifold=0):\n",
    "    dataset = QUESTDataset(df, tokenizer)\n",
    "    custom_collat_fn = dataset.collate_fn\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=custom_collat_fn, drop_last=True)\n",
    "    loader.num = len(loader)\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c3a1783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:28:51.048155Z",
     "iopub.status.busy": "2021-08-22T14:28:51.047387Z",
     "iopub.status.idle": "2021-08-22T14:28:51.050621Z",
     "shell.execute_reply": "2021-08-22T14:28:51.050992Z",
     "shell.execute_reply.started": "2021-08-22T11:05:00.079235Z"
    },
    "papermill": {
     "duration": 0.027132,
     "end_time": "2021-08-22T14:28:51.051155",
     "exception": false,
     "start_time": "2021-08-22T14:28:51.024023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader):\n",
    "    total_loss = []\n",
    "    total_spearman_val = []\n",
    "    for i in range(5): # 5\n",
    "        epoch_loss = []\n",
    "        epoch_spearman_val = []\n",
    "        for input_ids, seg_ids, attention_mask, target in tqdm(train_loader):\n",
    "            input_ids, seg_ids, attention_mask, target = (input_ids.to(device), seg_ids.to(device), \n",
    "                                                          attention_mask.to(device), target.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(input_ids, seg_ids, attention_mask)\n",
    "            loss = criterion(y_pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(loss.item())\n",
    "        mean_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "        total_loss.append(mean_loss)\n",
    "\n",
    "        del input_ids, seg_ids, attention_mask, target\n",
    "        gc.collect()\n",
    "        for input_ids, seg_ids, attention_mask, target in tqdm(val_loader):\n",
    "            input_ids, seg_ids, attention_mask = (input_ids.to(device), seg_ids.to(device), attention_mask.to(device))\n",
    "            y_pred = model(input_ids, seg_ids, attention_mask)\n",
    "            y_pred = y_pred.cpu().detach().numpy()\n",
    "            target = target.cpu().detach().numpy()\n",
    "            rho_val = np.mean([spearmanr(target[:, ind] + np.random.normal(0, 1e-7, target.shape[0]), y_pred[:, ind] + np.random.normal(0, 1e-7, y_pred.shape[0]), nan_policy='omit').correlation for ind in range(y_pred.shape[1])])\n",
    "            rho_val = round(rho_val, 4)\n",
    "            epoch_spearman_val.append(rho_val)\n",
    "\n",
    "        mean_spearman_val = sum(epoch_spearman_val) / len(epoch_spearman_val)\n",
    "        total_spearman_val.append(mean_spearman_val)\n",
    "        print(\"EPOCH\", i+1, \"-- TRAIN Loss:\", mean_loss, \"-- Spearman VAL:\", mean_spearman_val)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return total_loss, total_spearman_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99dfc603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:28:51.251299Z",
     "iopub.status.busy": "2021-08-22T14:28:51.250512Z",
     "iopub.status.idle": "2021-08-22T14:28:51.253850Z",
     "shell.execute_reply": "2021-08-22T14:28:51.254240Z",
     "shell.execute_reply.started": "2021-08-22T11:05:00.687056Z"
    },
    "papermill": {
     "duration": 0.191353,
     "end_time": "2021-08-22T14:28:51.254381",
     "exception": false,
     "start_time": "2021-08-22T14:28:51.063028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QUESTModel(nn.Module):\n",
    "    def __init__(self, transformer):\n",
    "        super(QUESTModel, self).__init__()\n",
    "        self.roberta = AutoModel.from_pretrained(transformer)\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size, 30)\n",
    "    \n",
    "    def forward(self, input_ids, seg_ids, attention_mask):\n",
    "        roberta_output = self.roberta(input_ids=input_ids, token_type_ids=seg_ids, attention_mask=attention_mask)\n",
    "        pooler_output = roberta_output[1]\n",
    "        out = self.classifier(pooler_output)\n",
    "        return out\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b832024b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:28:51.457980Z",
     "iopub.status.busy": "2021-08-22T14:28:51.457361Z",
     "iopub.status.idle": "2021-08-22T21:44:39.876858Z",
     "shell.execute_reply": "2021-08-22T21:44:39.877450Z",
     "shell.execute_reply.started": "2021-08-22T12:29:21.363822Z"
    },
    "papermill": {
     "duration": 26148.611224,
     "end_time": "2021-08-22T21:44:39.877711",
     "exception": false,
     "start_time": "2021-08-22T14:28:51.266487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been creating and moved to GPU\n",
      "Train and Valid Shapes are (4863, 41) (1216, 41)\n",
      "Preparing DataLoaders...\n",
      "Started training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:08<00:00,  1.06it/s]\n",
      "100%|██████████| 304/304 [02:15<00:00,  2.24it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 -- TRAIN Loss: 0.3907098813312044 -- Spearman VAL: 0.2408536184210527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:13<00:00,  1.05it/s]\n",
      "100%|██████████| 304/304 [02:16<00:00,  2.23it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2 -- TRAIN Loss: 0.36400956047905814 -- Spearman VAL: 0.2493200657894737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:20<00:00,  1.05it/s]\n",
      "100%|██████████| 304/304 [02:17<00:00,  2.22it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3 -- TRAIN Loss: 0.3500045690026303 -- Spearman VAL: 0.27554999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:22<00:00,  1.05it/s]\n",
      "100%|██████████| 304/304 [02:16<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4 -- TRAIN Loss: 0.3419937912819317 -- Spearman VAL: 0.26324407894736834\n",
      "Saving model....\n",
      "Model has been saved!\n",
      "Fold 1 is done!\n",
      "Fold: 2\n",
      "Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been creating and moved to GPU\n",
      "Train and Valid Shapes are (4863, 41) (1216, 41)\n",
      "Preparing DataLoaders...\n",
      "Started training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:20<00:00,  1.05it/s]\n",
      "100%|██████████| 304/304 [02:16<00:00,  2.23it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 -- TRAIN Loss: 0.39221839904785155 -- Spearman VAL: 0.23210394736842088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:22<00:00,  1.04it/s]\n",
      "100%|██████████| 304/304 [02:16<00:00,  2.22it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2 -- TRAIN Loss: 0.36655432304727686 -- Spearman VAL: 0.26112039473684184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:26<00:00,  1.04it/s]\n",
      "100%|██████████| 304/304 [02:18<00:00,  2.20it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3 -- TRAIN Loss: 0.35318150629477246 -- Spearman VAL: 0.2805049342105265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:28<00:00,  1.04it/s]\n",
      "100%|██████████| 304/304 [02:18<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4 -- TRAIN Loss: 0.3396624461613565 -- Spearman VAL: 0.2748901315789475\n",
      "Saving model....\n",
      "Model has been saved!\n",
      "Fold 2 is done!\n",
      "Fold: 3\n",
      "Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been creating and moved to GPU\n",
      "Train and Valid Shapes are (4863, 41) (1216, 41)\n",
      "Preparing DataLoaders...\n",
      "Started training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:35<00:00,  1.03it/s]\n",
      "100%|██████████| 304/304 [02:21<00:00,  2.15it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 -- TRAIN Loss: 0.39209907101505576 -- Spearman VAL: 0.23519868421052617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:36<00:00,  1.03it/s]\n",
      "100%|██████████| 304/304 [02:19<00:00,  2.17it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2 -- TRAIN Loss: 0.3649274524347282 -- Spearman VAL: 0.2584871710526316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:23<00:00,  1.04it/s]\n",
      "100%|██████████| 304/304 [02:16<00:00,  2.23it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3 -- TRAIN Loss: 0.3532154031741766 -- Spearman VAL: 0.27576611842105264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:24<00:00,  1.04it/s]\n",
      "100%|██████████| 304/304 [02:19<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4 -- TRAIN Loss: 0.3404721587528417 -- Spearman VAL: 0.26644934210526344\n",
      "Saving model....\n",
      "Model has been saved!\n",
      "Fold 3 is done!\n",
      "Fold: 4\n",
      "Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been creating and moved to GPU\n",
      "Train and Valid Shapes are (4863, 41) (1216, 41)\n",
      "Preparing DataLoaders...\n",
      "Started training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:31<00:00,  1.04it/s]\n",
      "100%|██████████| 304/304 [02:19<00:00,  2.18it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 -- TRAIN Loss: 0.3918881716796891 -- Spearman VAL: 0.23504440789473677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:32<00:00,  1.04it/s]\n",
      "100%|██████████| 304/304 [02:18<00:00,  2.19it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2 -- TRAIN Loss: 0.3697597707372634 -- Spearman VAL: 0.26495690789473697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:27<00:00,  1.04it/s]\n",
      "100%|██████████| 304/304 [02:18<00:00,  2.20it/s]\n",
      "  0%|          | 0/1215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3 -- TRAIN Loss: 0.3578720175802953 -- Spearman VAL: 0.2617976973684211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [19:27<00:00,  1.04it/s]\n",
      "100%|██████████| 304/304 [02:19<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4 -- TRAIN Loss: 0.3467442948263859 -- Spearman VAL: 0.2631138157894738\n",
      "Saving model....\n",
      "Model has been saved!\n",
      "Fold 4 is done!\n",
      "Fold: 5\n",
      "Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/1216 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been creating and moved to GPU\n",
      "Train and Valid Shapes are (4864, 41) (1215, 41)\n",
      "Preparing DataLoaders...\n",
      "Started training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1216/1216 [19:27<00:00,  1.04it/s]\n",
      "100%|██████████| 303/303 [02:17<00:00,  2.21it/s]\n",
      "  0%|          | 0/1216 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 -- TRAIN Loss: 0.38927347211804436 -- Spearman VAL: 0.23522508250825075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1216/1216 [19:27<00:00,  1.04it/s]\n",
      "100%|██████████| 303/303 [02:17<00:00,  2.21it/s]\n",
      "  0%|          | 0/1216 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2 -- TRAIN Loss: 0.3630618649828983 -- Spearman VAL: 0.25718316831683163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1216/1216 [19:29<00:00,  1.04it/s]\n",
      "100%|██████████| 303/303 [02:17<00:00,  2.20it/s]\n",
      "  0%|          | 0/1216 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3 -- TRAIN Loss: 0.35091120530361014 -- Spearman VAL: 0.26314785478547864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1216/1216 [19:33<00:00,  1.04it/s]\n",
      "100%|██████████| 303/303 [02:19<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4 -- TRAIN Loss: 0.33921235881892864 -- Spearman VAL: 0.2821765676567657\n",
      "Saving model....\n",
      "Model has been saved!\n",
      "Fold 5 is done!\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "RoBERTa = '../input/robertalarge'\n",
    "tokenizer = AutoTokenizer.from_pretrained(RoBERTa)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "kf = KFold(n_splits=5, random_state=0)\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_df)):\n",
    "    print(\"Fold:\", fold+1)\n",
    "    print(\"Creating model...\")\n",
    "    model = QUESTModel(RoBERTa)\n",
    "    model = model.to(device)\n",
    "    print(\"Model has been creating and moved to GPU\")\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "#     lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=2e-6)\n",
    "    sub_train_df, sub_val_df = train_df.iloc[train_index], train_df.iloc[val_index]\n",
    "    print(\"Train and Valid Shapes are\", sub_train_df.shape, sub_val_df.shape)\n",
    "    print(\"Preparing DataLoaders...\")\n",
    "    train_loader = get_train_val_loaders(sub_train_df, tokenizer)\n",
    "    val_loader = get_train_val_loaders(sub_val_df, tokenizer)\n",
    "    \n",
    "    print(\"Started training...\")\n",
    "    for i in range(4):\n",
    "        epoch_loss = []\n",
    "        epoch_spearman_val = []\n",
    "        for input_ids, seg_ids, attention_mask, target in tqdm(train_loader):\n",
    "            input_ids, seg_ids, attention_mask, target = (input_ids.to(device), seg_ids.to(device), \n",
    "                                                          attention_mask.to(device), target.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(input_ids, seg_ids, attention_mask)\n",
    "            loss = criterion(y_pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(loss.item())\n",
    "        \n",
    "#         lr_scheduler.step()\n",
    "        mean_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "        del input_ids, seg_ids, attention_mask, target\n",
    "        gc.collect()\n",
    "\n",
    "        for input_ids, seg_ids, attention_mask, target in tqdm(val_loader):\n",
    "            input_ids, seg_ids, attention_mask = (input_ids.to(device), seg_ids.to(device), attention_mask.to(device))\n",
    "            y_pred = model(input_ids, seg_ids, attention_mask)\n",
    "            y_pred = y_pred.cpu().detach().numpy()\n",
    "            target = target.cpu().detach().numpy()\n",
    "            rho_val = np.mean([spearmanr(target[:, ind] + np.random.normal(0, 1e-7, target.shape[0]), y_pred[:, ind] + np.random.normal(0, 1e-7, y_pred.shape[0]), nan_policy='omit').correlation for ind in range(y_pred.shape[1])])\n",
    "            rho_val = round(rho_val, 4)\n",
    "            epoch_spearman_val.append(rho_val)\n",
    "\n",
    "        mean_spearman_val = sum(epoch_spearman_val) / len(epoch_spearman_val)\n",
    "        print(\"EPOCH\", i+1, \"-- TRAIN Loss:\", mean_loss, \"-- Spearman VAL:\", mean_spearman_val)\n",
    "\n",
    "    print(\"Saving model....\")\n",
    "    torch.save(model.state_dict(), f'questRoBERTa_{fold}.pt')\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"Model has been saved!\")\n",
    "    print(\"Fold\", fold+1, \"is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ed340",
   "metadata": {
    "papermill": {
     "duration": 8.0564,
     "end_time": "2021-08-22T21:44:56.519391",
     "exception": false,
     "start_time": "2021-08-22T21:44:48.462991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26190.442831,
   "end_time": "2021-08-22T21:45:07.327892",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-22T14:28:36.885061",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
